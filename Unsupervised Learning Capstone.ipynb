{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at what text I can use. \n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 10 different books with 10 different authors.\n",
    "austen = gutenberg.raw('austen-emma.txt')\n",
    "bible = gutenberg.raw('bible-kjv.txt')\n",
    "blake = gutenberg.raw('blake-poems.txt')\n",
    "bryant = gutenberg.raw('bryant-stories.txt')\n",
    "buster = gutenberg.raw('burgess-busterbrown.txt')\n",
    "chesterton = gutenberg.raw('chesterton-thursday.txt')\n",
    "edgeworth = gutenberg.raw('edgeworth-parents.txt')\n",
    "milton = gutenberg.raw('milton-paradise.txt')\n",
    "shakes = gutenberg.raw('shakespeare-caesar.txt')\n",
    "whitman = gutenberg.raw('whitman-leaves.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    text = re.sub(r'CHAPTER \\d+', '', text)\n",
    "    text = re.sub(\"\\\\n\\\\n.*?\\\\n\\\\n\", '', text)\n",
    "  \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean documents\n",
    "austen = text_cleaner(austen)[:100000]\n",
    "# Bible was over the limit for nlp so I had to limit it.\n",
    "bible = text_cleaner(bible)[:100000]\n",
    "blake = text_cleaner(blake)[:100000]\n",
    "bryant = text_cleaner(bryant)[:100000]\n",
    "buster = text_cleaner(buster)[:100000]\n",
    "chesterton = text_cleaner(chesterton)[:100000]\n",
    "edgeworth = text_cleaner(edgeworth)[:100000]\n",
    "milton = text_cleaner(milton)[:100000]\n",
    "shakes = text_cleaner(shakes)[:100000]\n",
    "whitman = text_cleaner(whitman)[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "99989\n",
      "35855\n",
      "100000\n",
      "82085\n",
      "82085\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "books = [austen, bible, blake, bryant, buster, buster, chesterton,\n",
    "edgeworth, milton, shakes, whitman]\n",
    "\n",
    "for i in books:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spaCy and analyze the documents\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "austen_doc = nlp(austen)\n",
    "bible_doc = nlp(bible)\n",
    "blake_doc = nlp(blake)\n",
    "bryant_doc = nlp(bryant)\n",
    "buster_doc = nlp(buster)\n",
    "chesterton_doc = nlp(chesterton)\n",
    "edgeworth_doc = nlp(edgeworth)\n",
    "milton_doc = nlp(milton)\n",
    "shakes_doc = nlp(shakes)\n",
    "whitman_doc = nlp(whitman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into sentences\n",
    "austen_sents = [[sent, 'austen'] for sent in austen_doc.sents]\n",
    "bible_sents = [[sent, 'bible'] for sent in bible_doc.sents]\n",
    "blake_sents = [[sent, 'blake'] for sent in blake_doc.sents]\n",
    "bryant_sents = [[sent, 'bryant'] for sent in bryant_doc.sents]\n",
    "buster_sents = [[sent, 'buster'] for sent in buster_doc.sents]\n",
    "chesterton_sents = [[sent, 'chesterton'] for sent in chesterton_doc.sents]\n",
    "edgeworth_sents = [[sent, 'edgeworth'] for sent in edgeworth_doc.sents]\n",
    "milton_sents = [[sent, 'milton'] for sent in milton_doc.sents]\n",
    "shakes_sents = [[sent, 'shakes'] for sent in shakes_doc.sents]\n",
    "whitman_sents = [[sent, 'whitman'] for sent in whitman_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7196"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility function to create a list of the 1500 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1500)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "austen_words = bag_of_words(austen_doc)\n",
    "bible_words = bag_of_words(bible_doc)\n",
    "blake_words = bag_of_words(blake_doc)\n",
    "bryant_words = bag_of_words(bryant_doc)\n",
    "buster_words = bag_of_words(buster_doc)\n",
    "chesterton_words = bag_of_words(chesterton_doc)\n",
    "edgeworth_words = bag_of_words(edgeworth_doc)\n",
    "milton_words = bag_of_words(milton_doc)\n",
    "shakes_words = bag_of_words(shakes_doc)\n",
    "whitman_words = bag_of_words(whitman_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(austen_words + bible_words + blake_words + bryant_words +\n",
    "                        buster_words + chesterton_words + edgeworth_words +\n",
    "                        milton_words + shakes_words + whitman_words)\n",
    "\n",
    "# How many words we got?\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the sentences from the 10 novels into one data frame.\n",
    "sentences = pd.DataFrame(austen_sents + bible_sents + blake_sents + bryant_sents +\n",
    "                        buster_sents + chesterton_sents + edgeworth_sents +\n",
    "                        milton_sents + shakes_sents + whitman_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n",
      "Processing row 7000\n",
      "Processing row 7500\n",
      "Processing row 8000\n",
      "Processing row 8500\n",
      "Processing row 9000\n",
      "Processing row 9500\n",
      "Processing row 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>atelier</th>\n",
       "      <th>wanderer</th>\n",
       "      <th>casteth</th>\n",
       "      <th>flannel</th>\n",
       "      <th>bonnet</th>\n",
       "      <th>number</th>\n",
       "      <th>some</th>\n",
       "      <th>cost</th>\n",
       "      <th>fetch</th>\n",
       "      <th>...</th>\n",
       "      <th>pillow</th>\n",
       "      <th>covering</th>\n",
       "      <th>nest</th>\n",
       "      <th>loue</th>\n",
       "      <th>cheerfulness</th>\n",
       "      <th>gogol</th>\n",
       "      <th>emins</th>\n",
       "      <th>weep</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(CHAPTER, I, Emma, Woodhouse, ,, handsome, ,, ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(She, was, the, youngest, of, the, two, daught...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Her, mother, had, died, too, long, ago, for, ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Sixteen, years, had, Miss, Taylor, been, in, ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Between, _, them)</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature atelier wanderer casteth flannel bonnet number some cost fetch  \\\n",
       "0       0       0        0       0       0      0      0    0    0     0   \n",
       "1       0       0        0       0       0      0      0    0    0     0   \n",
       "2       0       0        0       0       0      0      0    0    0     0   \n",
       "3       0       0        0       0       0      0      0    0    0     0   \n",
       "4       0       0        0       0       0      0      0    0    0     0   \n",
       "\n",
       "      ...     pillow covering nest loue cheerfulness gogol emins weep  \\\n",
       "0     ...          0        0    0    0            0     0     0    0   \n",
       "1     ...          0        0    0    0            0     0     0    0   \n",
       "2     ...          0        0    0    0            0     0     0    0   \n",
       "3     ...          0        0    0    0            0     0     0    0   \n",
       "4     ...          0        0    0    0            0     0     0    0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (CHAPTER, I, Emma, Woodhouse, ,, handsome, ,, ...      austen  \n",
       "1  (She, was, the, youngest, of, the, two, daught...      austen  \n",
       "2  (Her, mother, had, died, too, long, ago, for, ...      austen  \n",
       "3  (Sixteen, years, had, Miss, Taylor, been, in, ...      austen  \n",
       "4                                 (Between, _, them)      austen  \n",
       "\n",
       "[5 rows x 7198 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that my models have been performing poorly, I decided to add the bag of words and common words features in order to see if I can obtain stronger results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf-idf function\n",
    "def document_freq(data, sentences, common_words, doc_names, doc_words):\n",
    "    \n",
    "    # initialize df\n",
    "    df = pd.DataFrame(columns = common_words)\n",
    "    df.iloc[:, 0] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    df.loc[:, common_words] = 0\n",
    "    df.rename(index={0:'df', 1:'cf', 2:'idf', 3:'austen', 4:'bible', 5:'blake',\n",
    "                                                  6:'bryant', 7:'buster', 8:'chesterton',\n",
    "                                                  9:'edgeworth', 10:'milton', 11:'shakes',\n",
    "                                                  12:'whitman'}, inplace=True)\n",
    "    \n",
    "    for word in common_words:\n",
    "        # find document frequency & collection frequency\n",
    "        df.loc['df', word] = data[data[word] > 0][word].count()\n",
    "        df.loc['cf', word] = data.loc[:, word].sum()\n",
    "        \n",
    "        # find idf\n",
    "        df.loc['idf', word] = np.log2(len(sentences)/df.loc['df', word])\n",
    "        \n",
    "    # assign the idf value to the documents\n",
    "    for word in df.columns:\n",
    "        for i in range(len(doc_names)):\n",
    "            if word in doc_words[i]:\n",
    "                df.loc[doc_names[i], word] = df.loc['idf', word]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>atelier</th>\n",
       "      <th>wanderer</th>\n",
       "      <th>casteth</th>\n",
       "      <th>flannel</th>\n",
       "      <th>bonnet</th>\n",
       "      <th>number</th>\n",
       "      <th>some</th>\n",
       "      <th>cost</th>\n",
       "      <th>fetch</th>\n",
       "      <th>...</th>\n",
       "      <th>brunswick</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>pillow</th>\n",
       "      <th>covering</th>\n",
       "      <th>nest</th>\n",
       "      <th>loue</th>\n",
       "      <th>cheerfulness</th>\n",
       "      <th>gogol</th>\n",
       "      <th>emins</th>\n",
       "      <th>weep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>10.518513</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>...</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>11.325868</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>9.866436</td>\n",
       "      <td>8.238405</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>8.07794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austen</th>\n",
       "      <td>10.518513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>8.07794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blake</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.866436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.07794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bryant</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.866436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buster</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgeworth</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milton</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.238405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.07794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitman</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.93355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.866436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.07794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 7196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature    atelier   wanderer    casteth    flannel     bonnet  \\\n",
       "df           7.000000   1.000000   2.000000   1.000000   1.000000   3.000000   \n",
       "cf           7.000000   1.000000   2.000000   1.000000   1.000000   3.000000   \n",
       "idf         10.518513  13.325868  12.325868  13.325868  13.325868  11.740905   \n",
       "austen      10.518513   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "bible        0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "blake        0.000000   0.000000  12.325868   0.000000   0.000000   0.000000   \n",
       "bryant       0.000000   0.000000   0.000000  13.325868   0.000000  11.740905   \n",
       "buster       0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "chesterton   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "edgeworth    0.000000   0.000000   0.000000   0.000000  13.325868   0.000000   \n",
       "milton       0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "shakes       0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "whitman      0.000000  13.325868   0.000000   0.000000   0.000000  11.740905   \n",
       "\n",
       "               number      some       cost      fetch    ...     brunswick  \\\n",
       "df          23.000000  21.00000   2.000000  15.000000    ...      2.000000   \n",
       "cf          25.000000  21.00000   2.000000  15.000000    ...      2.000000   \n",
       "idf          8.802306   8.93355  12.325868   9.418977    ...     12.325868   \n",
       "austen       8.802306   8.93355   0.000000   0.000000    ...     12.325868   \n",
       "bible        8.802306   0.00000   0.000000   9.418977    ...      0.000000   \n",
       "blake        0.000000   0.00000   0.000000   0.000000    ...      0.000000   \n",
       "bryant       8.802306   8.93355   0.000000   9.418977    ...      0.000000   \n",
       "buster       8.802306   0.00000   0.000000   0.000000    ...      0.000000   \n",
       "chesterton   0.000000   8.93355   0.000000   0.000000    ...      0.000000   \n",
       "edgeworth    8.802306   8.93355  12.325868   9.418977    ...      0.000000   \n",
       "milton       8.802306   8.93355   0.000000   0.000000    ...      0.000000   \n",
       "shakes       8.802306   8.93355   0.000000   9.418977    ...      0.000000   \n",
       "whitman      0.000000   8.93355   0.000000   9.418977    ...      0.000000   \n",
       "\n",
       "            yesterday     pillow   covering       nest       loue  \\\n",
       "df           4.000000   2.000000   2.000000  11.000000  34.000000   \n",
       "cf           4.000000   2.000000   2.000000  11.000000  34.000000   \n",
       "idf         11.325868  12.325868  12.325868   9.866436   8.238405   \n",
       "austen       0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "bible        0.000000   0.000000  12.325868   0.000000   0.000000   \n",
       "blake        0.000000   0.000000   0.000000   9.866436   0.000000   \n",
       "bryant       0.000000  12.325868   0.000000   9.866436   0.000000   \n",
       "buster      11.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "chesterton   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "edgeworth    0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "milton       0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "shakes      11.325868   0.000000   0.000000   0.000000   8.238405   \n",
       "whitman      0.000000   0.000000   0.000000   9.866436   0.000000   \n",
       "\n",
       "            cheerfulness      gogol      emins      weep  \n",
       "df              3.000000   7.000000   1.000000  38.00000  \n",
       "cf              3.000000   7.000000   1.000000  43.00000  \n",
       "idf            11.740905  10.518513  13.325868   8.07794  \n",
       "austen         11.740905   0.000000   0.000000   0.00000  \n",
       "bible           0.000000   0.000000  13.325868   8.07794  \n",
       "blake           0.000000   0.000000   0.000000   8.07794  \n",
       "bryant          0.000000   0.000000   0.000000   0.00000  \n",
       "buster          0.000000   0.000000   0.000000   0.00000  \n",
       "chesterton      0.000000  10.518513   0.000000   0.00000  \n",
       "edgeworth      11.740905   0.000000   0.000000   0.00000  \n",
       "milton          0.000000   0.000000   0.000000   0.00000  \n",
       "shakes          0.000000   0.000000   0.000000   8.07794  \n",
       "whitman         0.000000   0.000000   0.000000   8.07794  \n",
       "\n",
       "[13 rows x 7196 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create arrays to identify and hold my words.\n",
    "doc_names = ['austen', 'bible', 'blake', 'bryant', 'buster',\n",
    "            'chesterton', 'edgeworth', 'milton', 'shakes', 'whitman']\n",
    "doc_words = [austen_words, bible_words, blake_words, bryant_words, buster_words, chesterton_words,\n",
    "            edgeworth_words, milton_words, shakes_words, whitman_words]\n",
    "tf_idf = document_freq(word_counts, sentences, common_words, doc_names, doc_words)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "      <th>austen</th>\n",
       "      <th>bible</th>\n",
       "      <th>blake</th>\n",
       "      <th>bryant</th>\n",
       "      <th>buster</th>\n",
       "      <th>chesterton</th>\n",
       "      <th>edgeworth</th>\n",
       "      <th>milton</th>\n",
       "      <th>shakes</th>\n",
       "      <th>whitman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atelier</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.325868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wanderer</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casteth</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flannel</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           df   cf        idf     austen  bible      blake     bryant  buster  \\\n",
       "feature   7.0  7.0  10.518513  10.518513    0.0   0.000000   0.000000     0.0   \n",
       "atelier   1.0  1.0  13.325868   0.000000    0.0   0.000000   0.000000     0.0   \n",
       "wanderer  2.0  2.0  12.325868   0.000000    0.0  12.325868   0.000000     0.0   \n",
       "casteth   1.0  1.0  13.325868   0.000000    0.0   0.000000  13.325868     0.0   \n",
       "flannel   1.0  1.0  13.325868   0.000000    0.0   0.000000   0.000000     0.0   \n",
       "\n",
       "          chesterton  edgeworth  milton  shakes    whitman  \n",
       "feature          0.0   0.000000     0.0     0.0   0.000000  \n",
       "atelier          0.0   0.000000     0.0     0.0  13.325868  \n",
       "wanderer         0.0   0.000000     0.0     0.0   0.000000  \n",
       "casteth          0.0   0.000000     0.0     0.0   0.000000  \n",
       "flannel          0.0  13.325868     0.0     0.0   0.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make it so that the rows become the columns.\n",
    "tf_idf = tf_idf.T\n",
    "tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "      <th>austen</th>\n",
       "      <th>bible</th>\n",
       "      <th>blake</th>\n",
       "      <th>bryant</th>\n",
       "      <th>buster</th>\n",
       "      <th>chesterton</th>\n",
       "      <th>edgeworth</th>\n",
       "      <th>...</th>\n",
       "      <th>whitman</th>\n",
       "      <th>austen_threshold</th>\n",
       "      <th>bible_threshold</th>\n",
       "      <th>blake_threshold</th>\n",
       "      <th>bryant_threshold</th>\n",
       "      <th>buster_threshold</th>\n",
       "      <th>chesterton_threshold</th>\n",
       "      <th>edgeworth_threshold</th>\n",
       "      <th>milton_threshold</th>\n",
       "      <th>shakes_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atelier</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wanderer</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casteth</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flannel</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           df   cf        idf     austen  bible      blake     bryant  buster  \\\n",
       "feature   7.0  7.0  10.518513  10.518513    0.0   0.000000   0.000000     0.0   \n",
       "atelier   1.0  1.0  13.325868   0.000000    0.0   0.000000   0.000000     0.0   \n",
       "wanderer  2.0  2.0  12.325868   0.000000    0.0  12.325868   0.000000     0.0   \n",
       "casteth   1.0  1.0  13.325868   0.000000    0.0   0.000000  13.325868     0.0   \n",
       "flannel   1.0  1.0  13.325868   0.000000    0.0   0.000000   0.000000     0.0   \n",
       "\n",
       "          chesterton  edgeworth        ...           whitman  \\\n",
       "feature          0.0   0.000000        ...          0.000000   \n",
       "atelier          0.0   0.000000        ...         13.325868   \n",
       "wanderer         0.0   0.000000        ...          0.000000   \n",
       "casteth          0.0   0.000000        ...          0.000000   \n",
       "flannel          0.0  13.325868        ...          0.000000   \n",
       "\n",
       "          austen_threshold  bible_threshold  blake_threshold  \\\n",
       "feature                  0                0                0   \n",
       "atelier                  0                0                0   \n",
       "wanderer                 0                0                0   \n",
       "casteth                  0                0                0   \n",
       "flannel                  0                0                0   \n",
       "\n",
       "          bryant_threshold  buster_threshold  chesterton_threshold  \\\n",
       "feature                  0                 0                     0   \n",
       "atelier                  0                 0                     0   \n",
       "wanderer                 0                 0                     0   \n",
       "casteth                  1                 0                     0   \n",
       "flannel                  0                 0                     0   \n",
       "\n",
       "          edgeworth_threshold  milton_threshold  shakes_threshold  \n",
       "feature                     0                 0                 0  \n",
       "atelier                     0                 0                 0  \n",
       "wanderer                    0                 0                 0  \n",
       "casteth                     0                 0                 0  \n",
       "flannel                     1                 0                 0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a threshold to count and see which word belongs where.\n",
    "threshold = 13\n",
    "tf_idf['austen_threshold'] = 0\n",
    "tf_idf['bible_threshold'] = 0\n",
    "tf_idf['blake_threshold'] = 0\n",
    "tf_idf['bryant_threshold'] = 0\n",
    "tf_idf['buster_threshold'] = 0\n",
    "tf_idf['chesterton_threshold'] = 0\n",
    "tf_idf['edgeworth_threshold'] = 0\n",
    "tf_idf['milton_threshold'] = 0\n",
    "tf_idf['shakes_threshold'] = 0\n",
    "\n",
    "\n",
    "\n",
    "tf_idf['austen_threshold'] = np.where(tf_idf['austen'] > threshold, 1, 0)\n",
    "tf_idf['bible_threshold'] = np.where(tf_idf['bible'] > threshold, 1, 0)\n",
    "tf_idf['blake_threshold'] = np.where(tf_idf['blake'] > threshold, 1, 0)\n",
    "tf_idf['bryant_threshold'] = np.where(tf_idf['bryant'] > threshold, 1, 0)\n",
    "tf_idf['buster_threshold'] = np.where(tf_idf['buster'] > threshold, 1, 0)\n",
    "tf_idf['chesterton_threshold'] = np.where(tf_idf['chesterton'] > threshold, 1, 0)\n",
    "tf_idf['edgeworth_threshold'] = np.where(tf_idf['edgeworth'] > threshold, 1, 0)\n",
    "tf_idf['milton_threshold'] = np.where(tf_idf['milton'] > threshold, 1, 0)\n",
    "tf_idf['shakes_threshold'] = np.where(tf_idf['shakes'] > threshold, 1, 0)\n",
    "tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a way to determine which word goes into which group.\n",
    "# default with both\n",
    "tf_idf['source'] = 'multiple'\n",
    "\n",
    "# Create a method\n",
    "def determine_who(df):\n",
    "    # Create a loop that iterates through each row and determines where it goes.\n",
    "    for i in range(len(df)):\n",
    "        # make a counter\n",
    "        flag = 0\n",
    "        source = 'multiple'\n",
    "        \n",
    "        if (df.iloc[i, 13] == 1):\n",
    "            flag = 1\n",
    "            source = 'austen'\n",
    "            \n",
    "        if (df.iloc[i, 14] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'bible'\n",
    "            \n",
    "        if (df.iloc[i, 15] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'blake'\n",
    "            \n",
    "        if (df.iloc[i, 16] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'bryant'\n",
    "            \n",
    "        if (df.iloc[i, 17] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'buster'\n",
    "            \n",
    "        if (df.iloc[i, 18] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'chesterton'\n",
    "            \n",
    "        if (df.iloc[i, 19] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'edgeworth'\n",
    "            \n",
    "        if (df.iloc[i, 20] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'milton'\n",
    "            \n",
    "        if (df.iloc[i, 21] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'shakes'\n",
    "            \n",
    "            \n",
    "        df.iloc[i, 22] = source\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "      <th>austen</th>\n",
       "      <th>bible</th>\n",
       "      <th>blake</th>\n",
       "      <th>bryant</th>\n",
       "      <th>buster</th>\n",
       "      <th>chesterton</th>\n",
       "      <th>edgeworth</th>\n",
       "      <th>...</th>\n",
       "      <th>austen_threshold</th>\n",
       "      <th>bible_threshold</th>\n",
       "      <th>blake_threshold</th>\n",
       "      <th>bryant_threshold</th>\n",
       "      <th>buster_threshold</th>\n",
       "      <th>chesterton_threshold</th>\n",
       "      <th>edgeworth_threshold</th>\n",
       "      <th>milton_threshold</th>\n",
       "      <th>shakes_threshold</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>10.518513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atelier</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wanderer</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casteth</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bryant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flannel</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonnet</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetch</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.418977</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fog</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation</th>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>8.933550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>61.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.395130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.395130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.395130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.395130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spur</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reach'd</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18:19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shpi</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bryant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottomless</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closet</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trap</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.155943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.155943</td>\n",
       "      <td>10.155943</td>\n",
       "      <td>10.155943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bulrush</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.740905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sawcy</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.518513</td>\n",
       "      <td>8.518513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.518513</td>\n",
       "      <td>8.518513</td>\n",
       "      <td>8.518513</td>\n",
       "      <td>8.518513</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authority</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>12.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19:12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loued'st</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lieu</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>13.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bewilder</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.325868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sudden</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>8.802306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multiple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              df    cf        idf     austen      bible      blake     bryant  \\\n",
       "feature      7.0   7.0  10.518513  10.518513   0.000000   0.000000   0.000000   \n",
       "atelier      1.0   1.0  13.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "wanderer     2.0   2.0  12.325868   0.000000   0.000000  12.325868   0.000000   \n",
       "casteth      1.0   1.0  13.325868   0.000000   0.000000   0.000000  13.325868   \n",
       "flannel      1.0   1.0  13.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "bonnet       3.0   3.0  11.740905   0.000000   0.000000   0.000000  11.740905   \n",
       "number      23.0  25.0   8.802306   8.802306   8.802306   0.000000   8.802306   \n",
       "some        21.0  21.0   8.933550   8.933550   0.000000   0.000000   8.933550   \n",
       "cost         2.0   2.0  12.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "fetch       15.0  15.0   9.418977   0.000000   9.418977   0.000000   9.418977   \n",
       "fog          3.0   3.0  11.740905   0.000000   0.000000   0.000000   0.000000   \n",
       "generation  21.0  23.0   8.933550   8.933550   8.933550   8.933550   0.000000   \n",
       "city        61.0  67.0   7.395130   0.000000   7.395130   0.000000   7.395130   \n",
       "spur         2.0   2.0  12.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "reach'd      2.0   3.0  12.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "18:19        1.0   1.0  13.325868   0.000000  13.325868   0.000000   0.000000   \n",
       "shpi         1.0   1.0  13.325868   0.000000   0.000000   0.000000  13.325868   \n",
       "comedy       1.0   1.0  13.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "bottomless   1.0   1.0  13.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "closet       2.0   2.0  12.325868   0.000000   0.000000   0.000000  12.325868   \n",
       "trap         9.0   9.0  10.155943   0.000000   0.000000   0.000000  10.155943   \n",
       "bulrush      3.0   3.0  11.740905   0.000000   0.000000   0.000000  11.740905   \n",
       "sawcy        2.0   2.0  12.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "breakfast   28.0  30.0   8.518513   8.518513   0.000000   0.000000   8.518513   \n",
       "authority    2.0   2.0  12.325868  12.325868   0.000000   0.000000   0.000000   \n",
       "19:12        1.0   1.0  13.325868   0.000000  13.325868   0.000000   0.000000   \n",
       "loued'st     1.0   2.0  13.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "lieu         1.0   1.0  13.325868  13.325868   0.000000   0.000000   0.000000   \n",
       "bewilder     4.0   4.0  11.325868   0.000000   0.000000   0.000000   0.000000   \n",
       "sudden      23.0  23.0   8.802306   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "               buster  chesterton  edgeworth     ...      austen_threshold  \\\n",
       "feature      0.000000    0.000000   0.000000     ...                     0   \n",
       "atelier      0.000000    0.000000   0.000000     ...                     0   \n",
       "wanderer     0.000000    0.000000   0.000000     ...                     0   \n",
       "casteth      0.000000    0.000000   0.000000     ...                     0   \n",
       "flannel      0.000000    0.000000  13.325868     ...                     0   \n",
       "bonnet       0.000000    0.000000   0.000000     ...                     0   \n",
       "number       8.802306    0.000000   8.802306     ...                     0   \n",
       "some         0.000000    8.933550   8.933550     ...                     0   \n",
       "cost         0.000000    0.000000  12.325868     ...                     0   \n",
       "fetch        0.000000    0.000000   9.418977     ...                     0   \n",
       "fog          0.000000    0.000000   0.000000     ...                     0   \n",
       "generation   0.000000    0.000000   0.000000     ...                     0   \n",
       "city         0.000000    7.395130   0.000000     ...                     0   \n",
       "spur         0.000000    0.000000  12.325868     ...                     0   \n",
       "reach'd      0.000000    0.000000   0.000000     ...                     0   \n",
       "18:19        0.000000    0.000000   0.000000     ...                     0   \n",
       "shpi         0.000000    0.000000   0.000000     ...                     0   \n",
       "comedy       0.000000   13.325868   0.000000     ...                     0   \n",
       "bottomless   0.000000    0.000000   0.000000     ...                     0   \n",
       "closet       0.000000    0.000000   0.000000     ...                     0   \n",
       "trap        10.155943   10.155943   0.000000     ...                     0   \n",
       "bulrush      0.000000    0.000000   0.000000     ...                     0   \n",
       "sawcy        0.000000    0.000000   0.000000     ...                     0   \n",
       "breakfast    8.518513    8.518513   8.518513     ...                     0   \n",
       "authority    0.000000    0.000000   0.000000     ...                     0   \n",
       "19:12        0.000000    0.000000   0.000000     ...                     0   \n",
       "loued'st     0.000000    0.000000   0.000000     ...                     0   \n",
       "lieu         0.000000    0.000000   0.000000     ...                     1   \n",
       "bewilder     0.000000   11.325868   0.000000     ...                     0   \n",
       "sudden       8.802306    8.802306   8.802306     ...                     0   \n",
       "\n",
       "            bible_threshold  blake_threshold  bryant_threshold  \\\n",
       "feature                   0                0                 0   \n",
       "atelier                   0                0                 0   \n",
       "wanderer                  0                0                 0   \n",
       "casteth                   0                0                 1   \n",
       "flannel                   0                0                 0   \n",
       "bonnet                    0                0                 0   \n",
       "number                    0                0                 0   \n",
       "some                      0                0                 0   \n",
       "cost                      0                0                 0   \n",
       "fetch                     0                0                 0   \n",
       "fog                       0                0                 0   \n",
       "generation                0                0                 0   \n",
       "city                      0                0                 0   \n",
       "spur                      0                0                 0   \n",
       "reach'd                   0                0                 0   \n",
       "18:19                     1                0                 0   \n",
       "shpi                      0                0                 1   \n",
       "comedy                    0                0                 0   \n",
       "bottomless                0                0                 0   \n",
       "closet                    0                0                 0   \n",
       "trap                      0                0                 0   \n",
       "bulrush                   0                0                 0   \n",
       "sawcy                     0                0                 0   \n",
       "breakfast                 0                0                 0   \n",
       "authority                 0                0                 0   \n",
       "19:12                     1                0                 0   \n",
       "loued'st                  0                0                 0   \n",
       "lieu                      0                0                 0   \n",
       "bewilder                  0                0                 0   \n",
       "sudden                    0                0                 0   \n",
       "\n",
       "            buster_threshold  chesterton_threshold  edgeworth_threshold  \\\n",
       "feature                    0                     0                    0   \n",
       "atelier                    0                     0                    0   \n",
       "wanderer                   0                     0                    0   \n",
       "casteth                    0                     0                    0   \n",
       "flannel                    0                     0                    1   \n",
       "bonnet                     0                     0                    0   \n",
       "number                     0                     0                    0   \n",
       "some                       0                     0                    0   \n",
       "cost                       0                     0                    0   \n",
       "fetch                      0                     0                    0   \n",
       "fog                        0                     0                    0   \n",
       "generation                 0                     0                    0   \n",
       "city                       0                     0                    0   \n",
       "spur                       0                     0                    0   \n",
       "reach'd                    0                     0                    0   \n",
       "18:19                      0                     0                    0   \n",
       "shpi                       0                     0                    0   \n",
       "comedy                     0                     1                    0   \n",
       "bottomless                 0                     0                    0   \n",
       "closet                     0                     0                    0   \n",
       "trap                       0                     0                    0   \n",
       "bulrush                    0                     0                    0   \n",
       "sawcy                      0                     0                    0   \n",
       "breakfast                  0                     0                    0   \n",
       "authority                  0                     0                    0   \n",
       "19:12                      0                     0                    0   \n",
       "loued'st                   0                     0                    0   \n",
       "lieu                       0                     0                    0   \n",
       "bewilder                   0                     0                    0   \n",
       "sudden                     0                     0                    0   \n",
       "\n",
       "            milton_threshold  shakes_threshold      source  \n",
       "feature                    0                 0    multiple  \n",
       "atelier                    0                 0    multiple  \n",
       "wanderer                   0                 0    multiple  \n",
       "casteth                    0                 0      bryant  \n",
       "flannel                    0                 0   edgeworth  \n",
       "bonnet                     0                 0    multiple  \n",
       "number                     0                 0    multiple  \n",
       "some                       0                 0    multiple  \n",
       "cost                       0                 0    multiple  \n",
       "fetch                      0                 0    multiple  \n",
       "fog                        0                 0    multiple  \n",
       "generation                 0                 0    multiple  \n",
       "city                       0                 0    multiple  \n",
       "spur                       0                 0    multiple  \n",
       "reach'd                    0                 0    multiple  \n",
       "18:19                      0                 0       bible  \n",
       "shpi                       0                 0      bryant  \n",
       "comedy                     0                 0  chesterton  \n",
       "bottomless                 1                 0      milton  \n",
       "closet                     0                 0    multiple  \n",
       "trap                       0                 0    multiple  \n",
       "bulrush                    0                 0    multiple  \n",
       "sawcy                      0                 0    multiple  \n",
       "breakfast                  0                 0    multiple  \n",
       "authority                  0                 0    multiple  \n",
       "19:12                      0                 0       bible  \n",
       "loued'st                   0                 1      shakes  \n",
       "lieu                       0                 0      austen  \n",
       "bewilder                   0                 0    multiple  \n",
       "sudden                     0                 0    multiple  \n",
       "\n",
       "[30 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Was testing the output and accidentally created another row. \n",
    "tf_idf_final = determine_who(tf_idf)\n",
    "\n",
    "tf_idf_final.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and testing model \n",
    "Y = tf_idf_final['source']\n",
    "X = tf_idf_final[['df', 'cf', 'idf']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "The point of using clusters is to group the paragraphs together to see if the clusters group accordingly to their author. There will be several different clustering techniques, the first being\n",
    "\n",
    "## K-Means Clustering\n",
    "\n",
    "K-means clustering is an iterative algorithm that seeks to cluster based on minimizing the inertia (cost function) or the sum of squared differences between the mean of the cluster and the data points of the cluster. \n",
    "\n",
    "Normally, the data would have to be normalized before using K-Means so that the distance would be accurate but that has already been done up top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>austen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blake</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bryant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buster</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgeworth</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milton</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2696</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>834</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         0  1  2     3  4   5   6  7    8    9\n",
       "source                                             \n",
       "austen        0  0  0   162  0   0   0  0    0    0\n",
       "bible         0  0  0   464  0   0   0  0    0    0\n",
       "blake         0  0  0   130  0   0   0  0    0    0\n",
       "bryant        0  0  0   128  0   0   0  0    0    0\n",
       "buster        0  0  0    87  0   0   0  0    0    0\n",
       "chesterton    0  0  0   102  0   0   0  0    0    0\n",
       "edgeworth     0  0  0   108  0   0   0  0    0    0\n",
       "milton        0  0  0    32  0   0   0  0    0    0\n",
       "multiple    278  1  9  2696  1  34  54  4  834  103\n",
       "shakes        0  0  0   170  0   0   0  0    0    0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# I will use 10 clusters because I have 10 authors.\n",
    "# Initialize the model. \n",
    "kmeans = KMeans(n_clusters=10, init='k-means++', random_state=42, n_init=20)\n",
    "\n",
    "# Fit and predict the model. \n",
    "y_pred = kmeans.fit_predict(X_train)\n",
    "\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: -0.2043194\n",
      "Silhouette Score: 0.7133754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Evaluate the performance of the clusters\n",
    "\n",
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y_train, y_pred)))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X_train, y_pred, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted Rand Index is a function that measures the similarity of two assignments, ignoring permutations and with chance normalization. The score was negative which means that the similarity might as well be random. ARI has an accurate ground truth in the y-pred so it signals that the similarity isn't there.\n",
    "\n",
    "Silhouette Coefficient is the mean distance between a sample and all other points in the same class (a), the mean distance between a sample and all other points in the next nearest cluster (b), divided by whichever of the two values is highest. Scores around 0 indicate overlapping clusters. Score is higher when clusters are dense and well separated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a27937208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "# Use the elbow method to see what is the optimal amount of clusters.\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,20)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X_train)\n",
    "    kmeanModel.fit(X_train)\n",
    "    distortions.append(sum(np.min(cdist(X_train, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X_train.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "sns.set_style('darkgrid')\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow is actually around 6 clusters but I have to use 10 in order to see if the models can label the 10 authors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch K Means \n",
    "\n",
    "Mini Batch won't really change much since it is only used when PCA isn't run to reduce dimensionality and search for clusters in the reduced data. Mini Batch is useful if I want to keep all the data and if I have limited computational power or time. It works by randomly sampling subsets of the training data in each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>austen</th>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible</th>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blake</th>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bryant</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buster</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgeworth</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milton</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>2530</td>\n",
       "      <td>28</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>341</td>\n",
       "      <td>77</td>\n",
       "      <td>10</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakes</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          0   1    2  3   4   5    6   7   8    9\n",
       "source                                                \n",
       "austen       162   0    0  0   0   0    0   0   0    0\n",
       "bible        464   0    0  0   0   0    0   0   0    0\n",
       "blake        130   0    0  0   0   0    0   0   0    0\n",
       "bryant       128   0    0  0   0   0    0   0   0    0\n",
       "buster        87   0    0  0   0   0    0   0   0    0\n",
       "chesterton   102   0    0  0   0   0    0   0   0    0\n",
       "edgeworth    108   0    0  0   0   0    0   0   0    0\n",
       "milton        32   0    0  0   0   0    0   0   0    0\n",
       "multiple    2530  28  141  2  43  26  341  77  10  816\n",
       "shakes       170   0    0  0   0   0    0   0   0    0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Initialize the model. \n",
    "minikmeans = MiniBatchKMeans(n_clusters=10, init='k-means++', random_state=42, init_size=1000, batch_size=1000)\n",
    "\n",
    "# Predict and fit the model. \n",
    "y_pred2 = minikmeans.fit_predict(X_train)\n",
    "\n",
    "pd.crosstab(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: -0.2169946\n",
      "Silhouette Score: 0.6840309\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y_train, y_pred2)))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X_train, y_pred2, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did slightly worse than k-means but that is to be expected since this is just another rendition of the original k-means model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering\n",
    "\n",
    "Spectral Clustering is based on quantifying similarity between data points. Spectral clustering takes many different measures of similiarity. The two most common ones are nearest neighbor and the Gaussian kernel of the Euclidean distance. I will put in 10 clusters and the 10 eigenvectors with the 10 largest eigenvalues are extracted and the data is converted to the new 10 dimensional space. This will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import SpectralClustering\n",
    "# # Pick the number of clusters.\n",
    "# n_clusters= 10\n",
    "\n",
    "# # Initialize the model.\n",
    "# sc = SpectralClustering(n_clusters=n_clusters)\n",
    "\n",
    "# # Fit and predict the model.\n",
    "# y_pred3 = sc.fit_predict(X_train)\n",
    "\n",
    "# pd.crosstab(y_train, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would've shown the results the spectral clustering model but it took 11 hours and the program was still running. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n",
      "                df           cf          idf  cluster_assignment\n",
      "count  1051.000000  1051.000000  1051.000000              1051.0\n",
      "mean     13.883920    14.488107     9.601855                 0.0\n",
      "std       4.446918     4.623604     0.451306                 0.0\n",
      "min       6.000000     9.000000     8.682011                 0.0\n",
      "25%      10.000000    10.000000     9.238405                 0.0\n",
      "50%      13.000000    13.000000     9.625428                 0.0\n",
      "75%      17.000000    18.000000    10.003939                 0.0\n",
      "max      25.000000    27.000000    10.740905                 0.0\n",
      "1\n",
      "\n",
      "\n",
      "           df      cf       idf  cluster_assignment\n",
      "count     1.0     1.0  1.000000                 1.0\n",
      "mean   3454.0  4557.0  1.571815                 1.0\n",
      "std       NaN     NaN       NaN                 NaN\n",
      "min    3454.0  4557.0  1.571815                 1.0\n",
      "25%    3454.0  4557.0  1.571815                 1.0\n",
      "50%    3454.0  4557.0  1.571815                 1.0\n",
      "75%    3454.0  4557.0  1.571815                 1.0\n",
      "max    3454.0  4557.0  1.571815                 1.0\n",
      "2\n",
      "\n",
      "\n",
      "               df          cf        idf  cluster_assignment\n",
      "count   13.000000   13.000000  13.000000                13.0\n",
      "mean   348.076923  376.307692   4.895925                 2.0\n",
      "std     48.976970   54.450872   0.204533                 0.0\n",
      "min    287.000000  302.000000   4.608191                 2.0\n",
      "25%    299.000000  331.000000   4.722241                 2.0\n",
      "50%    358.000000  381.000000   4.842052                 2.0\n",
      "75%    389.000000  409.000000   5.101866                 2.0\n",
      "max    421.000000  459.000000   5.160961                 2.0\n",
      "3\n",
      "\n",
      "\n",
      "               df          cf        idf  cluster_assignment\n",
      "count   30.000000   30.000000  30.000000                30.0\n",
      "mean   213.633333  234.433333   5.598582                 3.0\n",
      "std     28.422288   36.603828   0.184685                 0.0\n",
      "min    168.000000  190.000000   5.196585                 3.0\n",
      "25%    191.000000  206.250000   5.494774                 3.0\n",
      "50%    208.500000  227.500000   5.621968                 3.0\n",
      "75%    227.750000  254.750000   5.748498                 3.0\n",
      "max    280.000000  307.000000   5.933550                 3.0\n",
      "4\n",
      "\n",
      "\n",
      "           df      cf       idf  cluster_assignment\n",
      "count     1.0     1.0  1.000000                 1.0\n",
      "mean   1313.0  1454.0  2.967216                 4.0\n",
      "std       NaN     NaN       NaN                 NaN\n",
      "min    1313.0  1454.0  2.967216                 4.0\n",
      "25%    1313.0  1454.0  2.967216                 4.0\n",
      "50%    1313.0  1454.0  2.967216                 4.0\n",
      "75%    1313.0  1454.0  2.967216                 4.0\n",
      "max    1313.0  1454.0  2.967216                 4.0\n",
      "5\n",
      "\n",
      "\n",
      "               df          cf         idf  cluster_assignment\n",
      "count  126.000000  126.000000  126.000000               126.0\n",
      "mean    74.714286   78.992063    7.127526                 5.0\n",
      "std     14.018192   14.488338    0.269274                 0.0\n",
      "min     48.000000   58.000000    6.611622                 5.0\n",
      "25%     63.000000   66.000000    6.916477                 5.0\n",
      "50%     72.500000   76.000000    7.145993                 5.0\n",
      "75%     85.000000   90.750000    7.348588                 5.0\n",
      "max    105.000000  111.000000    7.740905                 5.0\n",
      "6\n",
      "\n",
      "\n",
      "                df           cf          idf  cluster_assignment\n",
      "count  5568.000000  5568.000000  5568.000000              5568.0\n",
      "mean      2.683010     2.756645    12.222529                 6.0\n",
      "std       1.839994     1.908037     0.959062                 0.0\n",
      "min       1.000000     1.000000    10.325868                 6.0\n",
      "25%       1.000000     1.000000    11.325868                 6.0\n",
      "50%       2.000000     2.000000    12.325868                 6.0\n",
      "75%       4.000000     4.000000    13.325868                 6.0\n",
      "max       8.000000    11.000000    13.325868                 6.0\n",
      "7\n",
      "\n",
      "\n",
      "               df          cf       idf  cluster_assignment\n",
      "count    6.000000    6.000000  6.000000                 6.0\n",
      "mean   680.500000  757.333333  3.933110                 7.0\n",
      "std    118.849064  124.052677  0.245497                 0.0\n",
      "min    546.000000  603.000000  3.552728                 7.0\n",
      "25%    604.250000  665.250000  3.815734                 7.0\n",
      "50%    663.000000  763.500000  3.956953                 7.0\n",
      "75%    729.250000  846.000000  4.086928                 7.0\n",
      "max    875.000000  908.000000  4.233110                 7.0\n",
      "8\n",
      "\n",
      "\n",
      "               df          cf         idf  cluster_assignment\n",
      "count  335.000000  335.000000  335.000000               335.0\n",
      "mean    35.098507   36.850746    8.229010                 8.0\n",
      "std      8.106283    8.647892    0.321335                 0.0\n",
      "min     24.000000   26.000000    7.518513                 8.0\n",
      "25%     28.000000   29.000000    7.968316                 8.0\n",
      "50%     33.000000   35.000000    8.281473                 8.0\n",
      "75%     41.000000   43.000000    8.518513                 8.0\n",
      "max     56.000000   58.000000    8.740905                 8.0\n",
      "9\n",
      "\n",
      "\n",
      "               df          cf        idf  cluster_assignment\n",
      "count   65.000000   65.000000  65.000000                65.0\n",
      "mean   131.153846  140.507692   6.306353                 9.0\n",
      "std     19.570570   22.190315   0.213197                 0.0\n",
      "min    101.000000  111.000000   5.882924                 9.0\n",
      "25%    114.000000  119.000000   6.126195                 9.0\n",
      "50%    127.000000  138.000000   6.337183                 9.0\n",
      "75%    147.000000  161.000000   6.492978                 9.0\n",
      "max    174.000000  185.000000   6.667656                 9.0\n"
     ]
    }
   ],
   "source": [
    "cluster_pred = KMeans(n_clusters=10, random_state=42).fit_predict(X)\n",
    "X_pred = X.copy()\n",
    "X_pred['cluster_assignment'] = cluster_pred\n",
    "\n",
    "cluster_dataframes = {}\n",
    "for n_clust in range(10):\n",
    "    cluster_dataframes[n_clust] = X_pred.loc[X_pred['cluster_assignment'] == n_clust]\n",
    "\n",
    "for name, frame in cluster_dataframes.items():\n",
    "    print(name)\n",
    "    print('\\n')\n",
    "    print(frame.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a problem. For the clusters I don't know what word is what word. To properly show the information of the clusters I will only use the part of speeches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis\n",
    "\n",
    "Previously, my data set had a lot of data in it. I decided in order to remedy this by running the LSA which is a dimension reduction technique (PCA) on the tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and testing model \n",
    "Y2 = tf_idf_final['source']\n",
    "X2 = tf_idf_final.drop(['source'], axis=1)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, \n",
    "                                                    Y2,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 99.62390043196956\n",
      "Component 0:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Buffer has wrong number of dimensions (expected 1, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-f47ecb9977ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Component {}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas_by_component\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# other: fancy integer or otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'getitem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# translate to locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     def _format_native_types(self, na_rep='', float_format=None, decimal='.',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   3455\u001b[0m         \"\"\"\n\u001b[1;32m   3456\u001b[0m         start_slice, end_slice = self.slice_locs(start, end, step=step,\n\u001b[0;32m-> 3457\u001b[0;31m                                                  kind=kind)\n\u001b[0m\u001b[1;32m   3458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3459\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   3656\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3658\u001b[0;31m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3660\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   3586\u001b[0m         \u001b[0;31m# we need to look up the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3587\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3588\u001b[0;31m             \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_only_exact_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3589\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_loc_only_exact_matches\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3555\u001b[0m         \u001b[0mget_slice_bound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m         \"\"\"\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         return super(Float64Index, self).get_loc(key, method=method,\n\u001b[0;32m--> 404\u001b[0;31m                                                  tolerance=tolerance)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2523\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._ensure_mapping_populated\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from  to 10.\n",
    "svd= TruncatedSVD(10)\n",
    "\n",
    "# Train the data for features since there's non tf-idf data in the features section.\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X2_train)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X2_train)\n",
    "for i in range(10):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1         2         3         4         5  \\\n",
      "num_author                                                               \n",
      "7           0.994814 -0.078265 -0.047750  0.018966  0.039749 -0.000720   \n",
      "6           0.999397  0.028364 -0.003980  0.016228  0.011007 -0.000556   \n",
      "4           0.996887  0.048178 -0.044709  0.028453  0.032968 -0.000390   \n",
      "4           0.995494 -0.074779  0.033321  0.011814 -0.046359 -0.000608   \n",
      "1           0.992685 -0.067442  0.061015  0.032824  0.070390  0.012494   \n",
      "8           0.997630  0.028415 -0.029086 -0.050091  0.023822  0.000005   \n",
      "7           0.998380  0.006345 -0.001254 -0.045072 -0.034113 -0.000282   \n",
      "7           0.995870 -0.051024  0.030951 -0.047133  0.049564 -0.001501   \n",
      "7           0.992591 -0.010588  0.111428 -0.042053  0.021503 -0.001675   \n",
      "6           0.991230  0.113395 -0.030904 -0.056383 -0.021682  0.000220   \n",
      "4           0.999159  0.036888  0.007770  0.015427  0.000401  0.004040   \n",
      "6           0.999377 -0.026540  0.010444  0.013944 -0.015050  0.002849   \n",
      "7           0.977153 -0.081800  0.036894  0.187503 -0.044265  0.000521   \n",
      "7           0.997081 -0.012925  0.014712 -0.021063  0.070618 -0.002288   \n",
      "10          0.958966  0.007560  0.177912 -0.117952 -0.102563  0.047584   \n",
      "1           0.998320  0.031016 -0.030534 -0.006664 -0.037670  0.000188   \n",
      "7           0.968603 -0.040602 -0.008830  0.088541  0.228464 -0.004140   \n",
      "9           0.956069  0.223825 -0.176428 -0.055061 -0.040929  0.001115   \n",
      "9           0.936071 -0.294256  0.043469  0.146416 -0.117701 -0.000429   \n",
      "7           0.968746 -0.040523 -0.008769  0.088452  0.227964 -0.004189   \n",
      "4           0.997828  0.020109 -0.052667 -0.004960  0.033698 -0.000007   \n",
      "4           0.997744 -0.023266  0.037950 -0.038081 -0.032774 -0.000469   \n",
      "2           0.997092  0.058894 -0.002289 -0.021782  0.041909  0.001899   \n",
      "6           0.985931 -0.122779  0.104710 -0.010129 -0.042391 -0.000731   \n",
      "9           0.974410 -0.184984  0.062386 -0.045287  0.101760 -0.002733   \n",
      "1           0.984757 -0.158718 -0.023119 -0.061831  0.026424 -0.001499   \n",
      "1           0.751025  0.053197 -0.634821 -0.169073 -0.039290  0.001891   \n",
      "7           0.990489 -0.121981  0.047758 -0.041929 -0.003447  0.000035   \n",
      "10          0.981031  0.178713  0.072467  0.011531  0.015981 -0.000009   \n",
      "1           0.977963 -0.082201 -0.101007  0.080608 -0.141884  0.000793   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "1           0.989773 -0.076973  0.066351 -0.011492  0.099435 -0.001097   \n",
      "1           0.991690 -0.127796  0.006164 -0.011784  0.006294 -0.001350   \n",
      "4           0.995349 -0.028840  0.088331  0.018097  0.017827 -0.000910   \n",
      "9           0.975862 -0.189180  0.033205 -0.074051 -0.072887 -0.000218   \n",
      "1           0.982692 -0.162208 -0.001820  0.036401 -0.081707  0.000104   \n",
      "1           0.991837 -0.105012  0.054924 -0.030301  0.035924 -0.001893   \n",
      "10          0.959514 -0.239406  0.029594  0.019725 -0.144057 -0.000358   \n",
      "7           0.995210 -0.039585 -0.080058  0.024512 -0.031300  0.000133   \n",
      "1           0.996581 -0.074133 -0.006363 -0.035419 -0.005879 -0.001067   \n",
      "1           0.982740 -0.174331 -0.017823  0.003482  0.059061 -0.002701   \n",
      "7           0.998653 -0.032105 -0.015339  0.036735  0.008743 -0.000703   \n",
      "7           0.969026 -0.223123  0.093177 -0.018597 -0.042676  0.014331   \n",
      "7           0.996758 -0.011680 -0.027061 -0.074304  0.009149 -0.000431   \n",
      "8           0.998891  0.012434 -0.037049 -0.024945  0.008154 -0.000675   \n",
      "1           0.978789 -0.125712 -0.035298  0.143979 -0.064742 -0.000335   \n",
      "8           0.972611  0.084569 -0.144940  0.145735 -0.067960  0.002403   \n",
      "7           0.997150 -0.067567 -0.017711 -0.020545 -0.019737 -0.000660   \n",
      "7           0.995385 -0.051677  0.033535 -0.055810  0.038034  0.020930   \n",
      "1           0.949546 -0.260148  0.100258 -0.118315  0.028926  0.008721   \n",
      "1           0.993447  0.101946 -0.017325 -0.004558  0.048430 -0.000928   \n",
      "1           0.991491 -0.023858  0.059694  0.014837  0.112197 -0.002083   \n",
      "1           0.963851 -0.195568  0.009092  0.180651  0.000445 -0.001050   \n",
      "6           0.989732  0.118540  0.069225  0.015493 -0.036682  0.000900   \n",
      "7           0.967736 -0.041199 -0.008642  0.088599  0.229147 -0.017068   \n",
      "10          0.972789  0.216626  0.068256 -0.000695 -0.045765  0.000914   \n",
      "6           0.984390  0.016747 -0.129225 -0.113310 -0.034020  0.000163   \n",
      "1           0.993861  0.092260 -0.058716  0.000896  0.016736 -0.000144   \n",
      "4           0.995115 -0.028900 -0.080862  0.027429 -0.040250  0.000771   \n",
      "1           0.999022 -0.012941  0.018611 -0.031098 -0.021764 -0.000548   \n",
      "6           0.992596 -0.010582  0.111409 -0.042046  0.021435 -0.001064   \n",
      "\n",
      "                   6         7         8         9  \n",
      "num_author                                          \n",
      "7          -0.000082  0.000152 -0.000112 -0.000255  \n",
      "6          -0.000220  0.000085 -0.000072 -0.000158  \n",
      "4          -0.000357  0.000192  0.000106 -0.000106  \n",
      "4           0.000017 -0.000186 -0.000580 -0.000189  \n",
      "1          -0.003160 -0.002480 -0.000335 -0.010055  \n",
      "8           0.001935  0.000116 -0.000397  0.000744  \n",
      "7          -0.000209 -0.000259 -0.000327 -0.000286  \n",
      "7          -0.000700  0.000180 -0.000199 -0.000444  \n",
      "7          -0.000210  0.000060 -0.000461 -0.000146  \n",
      "6          -0.000333 -0.000204  0.000264 -0.000134  \n",
      "4          -0.000816 -0.001048 -0.000243 -0.001892  \n",
      "6          -0.000315 -0.000814 -0.000153 -0.001671  \n",
      "7          -0.000902 -0.000282  0.000351 -0.000764  \n",
      "7          -0.002044  0.000752 -0.000239 -0.002291  \n",
      "10         -0.043582  0.119174  0.062095  0.044958  \n",
      "1          -0.000425 -0.000049  0.000038 -0.000220  \n",
      "7           0.001781  0.003327  0.003721  0.000547  \n",
      "9          -0.000375  0.000196  0.000673  0.000203  \n",
      "9           0.000433  0.001084 -0.001468 -0.000134  \n",
      "7          -0.000517  0.001702 -0.000326 -0.000834  \n",
      "4          -0.000614  0.000017 -0.000007 -0.000194  \n",
      "4          -0.000186 -0.000261 -0.000307 -0.000208  \n",
      "2           0.008754  0.000187 -0.001019  0.004654  \n",
      "6          -0.000344 -0.000187 -0.000019 -0.000035  \n",
      "9           0.000114  0.000994 -0.000353  0.000330  \n",
      "1          -0.001664  0.000230 -0.000622 -0.001415  \n",
      "1          -0.000333  0.000032  0.000847  0.000053  \n",
      "7           0.000961  0.000113 -0.000168  0.000678  \n",
      "10         -0.000461 -0.000059  0.000298 -0.000092  \n",
      "1          -0.000028  0.000083 -0.000287  0.000196  \n",
      "...              ...       ...       ...       ...  \n",
      "1          -0.001260  0.000456  0.000310  0.000284  \n",
      "1          -0.000756  0.001101  0.000255 -0.000107  \n",
      "4          -0.000131 -0.000127 -0.000557 -0.000139  \n",
      "9           0.002006  0.000164 -0.000458  0.001096  \n",
      "1           0.000388 -0.000511  0.000246  0.000410  \n",
      "1          -0.001456  0.000497 -0.000117 -0.001236  \n",
      "10         -0.000101 -0.000408 -0.000535  0.000038  \n",
      "7          -0.000214 -0.000116 -0.000112 -0.000176  \n",
      "1          -0.000367  0.000037 -0.000480 -0.000273  \n",
      "1          -0.002155  0.000484 -0.000113 -0.000943  \n",
      "7          -0.000329  0.000083 -0.000110 -0.000176  \n",
      "7          -0.002749 -0.003875  0.011262 -0.000762  \n",
      "7          -0.000459 -0.000138 -0.000260 -0.000309  \n",
      "8          -0.000026  0.000125 -0.000171  0.000039  \n",
      "1           0.000061  0.000212 -0.000273 -0.000101  \n",
      "8          -0.000806  0.001701  0.000850  0.000739  \n",
      "7          -0.000083 -0.000081 -0.000357 -0.000049  \n",
      "7          -0.006882  0.018808 -0.002751 -0.002233  \n",
      "1          -0.016300 -0.004148  0.071551  0.017901  \n",
      "1          -0.001153  0.000469  0.000114 -0.001024  \n",
      "1          -0.000406  0.000375 -0.000134 -0.000314  \n",
      "1          -0.002600  0.002387 -0.000469 -0.003675  \n",
      "6          -0.000647 -0.000464  0.000266  0.000003  \n",
      "7          -0.020245  0.011029 -0.005927 -0.022329  \n",
      "10         -0.000318 -0.000468  0.000307 -0.000187  \n",
      "6          -0.000256 -0.000224 -0.000104 -0.000178  \n",
      "1          -0.000253  0.000043  0.000206 -0.000040  \n",
      "4          -0.000511 -0.000163 -0.000015 -0.000100  \n",
      "1          -0.000269 -0.000157 -0.000119 -0.000082  \n",
      "6          -0.000111 -0.000094 -0.000375 -0.000091  \n",
      "\n",
      "[28278 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "author_by_component=pd.DataFrame(X_train_lsa,index=y2_train)\n",
    "\n",
    "print(author_by_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It captured a lot of the variance of the data, perhaps too much. Lets check the sentence similarity. \n",
    "\n",
    "## Sentence Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f3037b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 As for her mother, she dotes upon her, as well she may; for I should myself if I had half such a daughter;\n",
      "1 At the moment when he announced himself as ready to stand for the post of Thursday, a roar of excitement and assent broke forth, and became uncontrollable, and at the same moment Gregory sprang to his feet, with foam upon his mouth, and shouted against the shouting.\n",
      "2 A brave little company of pioneers from the Atlantic coast crossed the Mississippi River and journeyed across the plains of Central North America in big covered wagons with many horses, and finally succeeded in climbing to the top of the great Rockies and down again into a valley in the very midst of the mountains.\n",
      "3 When the corn was ripe the mother Lark watched very carefully to see if there were any sign of the reapers' coming, for she knew that when they came their sharp knives would cut down the nest and hurt the baby Larks.\n",
      "4 that_,\" said Mr. Knightley, feelingly; and for a moment or two he had done.\n",
      "5 O thou in Heaven and Earth the only peace Found out for mankind under wrath, O thou My sole complacence!\n",
      "6 The pistol missed fire, for it was charged with some of the damaged powder which the Jew had bought that evening from the firework maker, and which he had sold as excellent immediately afterwards to his favourite customers the robbers who met at his house.\n",
      "7 Loveit thanked him, and was overjoyed at the thought of possessing this top. \"\n",
      "8 Enter WHEELER and BURSAL.\n",
      "9 We all lament the sad decease of the heroic worker who occupied the post until last week.\n"
     ]
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "print('Key:')\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Classification Models \n",
    "\n",
    "I'm going to attempt the supervised classification models to see how well the different models perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set score without clustering:0.82103(+/- 0.010)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the random forest model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Train and fit the model.\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_scores = cross_val_score(rfc, X_train, y_train, cv=5)\n",
    "\n",
    "print('\\nTraining set score without clustering:{:.5f}(+/- {:.3f})'.format(rfc_scores.mean(), rfc_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set score without clustering:0.82103(+/- 0.010)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model.\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model.\n",
    "train = lr.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the cross val score\n",
    "lr_scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "print('\\nTraining set score without clustering:{:.5f}(+/- {:.3f})'.format(lr_scores.mean(), lr_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set score without clustering:0.82103(+/- 0.010)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "clf_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print('\\nTraining set score without clustering:{:.5f}(+/- {:.3f})'.format(clf_scores.mean(), clf_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameters\n",
    "\n",
    "Since the gradient boosting model did the best I will try to increase that model's score for the clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8210116731517509\n",
      "Best Parameters: {'loss': 'deviance', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set of parameters to test for best score in Grid Search CV\n",
    "clf_params = {'loss':['deviance'],\n",
    "             'max_depth':[2,4,6],\n",
    "             'max_features':['auto'],\n",
    "             'n_estimators':[50,100,200,500]}\n",
    "\n",
    "#fitting model and printing best parameters and score from model\n",
    "grid_clf = GridSearchCV(clf, clf_params, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score:', grid_clf.best_score_)\n",
    "best_params_clf = grid_clf.best_params_\n",
    "print('Best Parameters:', best_params_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81625115, 0.81532779, 0.82020389, 0.82451253, 0.82883721])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     austen       0.00      0.00      0.00        57\n",
      "      bible       0.33      0.99      0.49       160\n",
      "      blake       0.00      0.00      0.00        42\n",
      "     bryant       0.00      0.00      0.00        48\n",
      "     buster       0.00      0.00      0.00        27\n",
      " chesterton       0.00      0.00      0.00        33\n",
      "  edgeworth       0.00      0.00      0.00        43\n",
      "     milton       0.00      0.00      0.00        13\n",
      "   multiple       0.99      0.99      0.99      1311\n",
      "     shakes       0.00      0.00      0.00        65\n",
      "\n",
      "avg / total       0.75      0.81      0.77      1799\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "clf_pred = clf.predict(X_test)\n",
    "\n",
    "# Create a classification report.\n",
    "print(classification_report(y_test, clf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
