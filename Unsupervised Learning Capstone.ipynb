{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at what text I can use. \n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 10 different books with 10 different authors.\n",
    "austen = gutenberg.raw('austen-emma.txt')\n",
    "bible = gutenberg.raw('bible-kjv.txt')\n",
    "blake = gutenberg.raw('blake-poems.txt')\n",
    "bryant = gutenberg.raw('bryant-stories.txt')\n",
    "buster = gutenberg.raw('burgess-busterbrown.txt')\n",
    "chesterton = gutenberg.raw('chesterton-thursday.txt')\n",
    "edgeworth = gutenberg.raw('edgeworth-parents.txt')\n",
    "milton = gutenberg.raw('milton-paradise.txt')\n",
    "shakes = gutenberg.raw('shakespeare-caesar.txt')\n",
    "whitman = gutenberg.raw('whitman-leaves.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    text = re.sub(r'CHAPTER \\d+', '', text)\n",
    "    text = re.sub(\"\\\\n\\\\n.*?\\\\n\\\\n\", '', text)\n",
    "  \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean documents\n",
    "austen = text_cleaner(austen)\n",
    "# Bible was over the limit for nlp so I had to limit it.\n",
    "bible = text_cleaner(bible)[:99990]\n",
    "blake = text_cleaner(blake)\n",
    "bryant = text_cleaner(bryant)\n",
    "buster = text_cleaner(buster)\n",
    "chesterton = text_cleaner(chesterton)\n",
    "edgeworth = text_cleaner(edgeworth)\n",
    "milton = text_cleaner(milton)\n",
    "shakes = text_cleaner(shakes)\n",
    "whitman = text_cleaner(whitman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spaCy and analyze the documents\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "austen_doc = nlp(austen)\n",
    "bible_doc = nlp(bible)\n",
    "blake_doc = nlp(blake)\n",
    "bryant_doc = nlp(bryant)\n",
    "buster_doc = nlp(buster)\n",
    "chesterton_doc = nlp(chesterton)\n",
    "edgeworth_doc = nlp(edgeworth)\n",
    "milton_doc = nlp(milton)\n",
    "shakes_doc = nlp(shakes)\n",
    "whitman_doc = nlp(whitman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into sentences\n",
    "austen_sents = [[sent, 'austen'] for sent in austen_doc.sents]\n",
    "bible_sents = [[sent, 'bible'] for sent in bible_doc.sents]\n",
    "bryant_sents = [[sent, 'bryant'] for sent in bryant_doc.sents]\n",
    "buster_sents = [[sent, 'buster'] for sent in buster_doc.sents]\n",
    "chesterton_sents = [[sent, 'chesterton'] for sent in chesterton_doc.sents]\n",
    "edgeworth_sents = [[sent, 'edgeworth'] for sent in edgeworth_doc.sents]\n",
    "milton_sents = [[sent, 'milton'] for sent in milton_doc.sents]\n",
    "shakes_sents = [[sent, 'shakes'] for sent in shakes_doc.sents]\n",
    "whitman_sents = [[sent, 'whitman'] for sent in whitman_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the sentences from the 10 novels into one data frame.\n",
    "sentences = pd.DataFrame(austen_sents + bible_sents + bryant_sents +\n",
    "                        buster_sents + chesterton_sents + edgeworth_sents +\n",
    "                        milton_sents + shakes_sents + whitman_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CHAPTER, I, Emma, Woodhouse, ,, handsome, ,, ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(She, was, the, youngest, of, the, two, daught...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Her, mother, had, died, too, long, ago, for, ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Sixteen, years, had, Miss, Taylor, been, in, ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Between, _, them)</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  (CHAPTER, I, Emma, Woodhouse, ,, handsome, ,, ...  austen\n",
       "1  (She, was, the, youngest, of, the, two, daught...  austen\n",
       "2  (Her, mother, had, died, too, long, ago, for, ...  austen\n",
       "3  (Sixteen, years, had, Miss, Taylor, been, in, ...  austen\n",
       "4                                 (Between, _, them)  austen"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a title to the columns so we know what we are looking at.\n",
    "sentences.columns = ['text', 'author']\n",
    "\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37215, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the size of the data. \n",
    "sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      object\n",
       "author    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I tried vectorizing before but the program wouldn't run.\n",
    "# The error said that it wanted string type data so I checked my data type.\n",
    "sentences.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally, sentences was an object type, need to convert it to str type.\n",
    "sentences['text'] = sentences['text'].astype('str') \n",
    "sentences['author'] = sentences['author'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and testing data set. \n",
    "X = sentences['text']\n",
    "y = sentences['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "\n",
    "## Tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10131\n",
      "Original sentence: Oh no!\n",
      "Tf_idf vector: {'Shake': 0.533733191309191, 'Corkscrew': 0.4179025907423565, 'fellow': 0.36685343522395064, 'honest': 0.38448314112456033, 'hands': 0.31609340947531134, 'glad': 0.3499317762019466, 'said': 0.188971651026113}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                            min_df=4,\n",
    "                            stop_words='english',\n",
    "                            lowercase=False,\n",
    "                            use_idf=True,\n",
    "                            norm=u'l2',\n",
    "                            smooth_idf=True)\n",
    "# Applying the vectorizer\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "print('Number of features: {}'.format(X_tfidf.get_shape()[1]))\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Reshape vectorizer to readable content\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "# Number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "# A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "# List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# For each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "# Keep in mind that the log base 2 of 1 is 0, \n",
    "# so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[100])\n",
    "print('Tf_idf vector:', tfidf_bypara[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data.\n",
    "from sklearn.preprocessing import normalize\n",
    "X_norm = normalize(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - spaCy\n",
    "\n",
    "Rerun NLP in order to tokenize each sentence to be able to extract information about parts of speech to add as features in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating spaCy\n",
    "nlp = spacy.load('en')\n",
    "X_train_words = []\n",
    "\n",
    "for row in X_train:\n",
    "    # Processing each row for tokens\n",
    "    row_doc = nlp(row)\n",
    "    # Calculating length of each sentence\n",
    "    sent_len = len(row_doc) \n",
    "    # Initializing counts of different parts of speech\n",
    "    advs = 0\n",
    "    verb = 0\n",
    "    noun = 0\n",
    "    adj = 0\n",
    "    for token in row_doc:\n",
    "        # Identifying each part of speech and adding to counts\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj +=1\n",
    "    # Creating a list of all features for each sentence\n",
    "    X_train_words.append([row_doc, advs, verb, noun, adj, sent_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to label each of these new features, I need to re index the y_train data\n",
    "y_train_new = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoW</th>\n",
       "      <th>Adv</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Adj</th>\n",
       "      <th>Sent_len</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(I, have, said, you, should, speak, presently, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(And, I, see, very, few, pearls, in, the, room...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>chesterton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(O, Cicero, ,, I, haue, seene, Tempests, ,, wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>whitman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(You, see, he, was, n't, well, enough, acquain...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(It, is, I, ,, you, women, ,, I, make, my, way...</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>whitman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BoW  Adv  Verb  Noun  Adj  \\\n",
       "0  (I, have, said, you, should, speak, presently, .)    1     4     0    0   \n",
       "1  (And, I, see, very, few, pearls, in, the, room...    1     1     3    1   \n",
       "2  (O, Cicero, ,, I, haue, seene, Tempests, ,, wh...    1     7     7    1   \n",
       "3  (You, see, he, was, n't, well, enough, acquain...    7     6     1    2   \n",
       "4  (It, is, I, ,, you, women, ,, I, make, my, way...    6    18     8    8   \n",
       "\n",
       "   Sent_len      author  \n",
       "0         8      austen  \n",
       "1        12  chesterton  \n",
       "2        42     whitman  \n",
       "3        29      austen  \n",
       "4        87     whitman  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the new features together with their respective authors.\n",
    "# Create a data frame for the features first.\n",
    "txt_bow = pd.DataFrame(data=X_train_words, columns=['BoW', 'Adv', 'Verb', 'Noun',\n",
    "                                                   'Adj', 'Sent_len'])\n",
    "# Add the author data into the data frame.\n",
    "txt_bow = pd.concat([txt_bow, y_train_new], ignore_index=False, axis=1)\n",
    "txt_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoW</th>\n",
       "      <th>Adv</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Adj</th>\n",
       "      <th>Sent_len</th>\n",
       "      <th>author</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>10121</th>\n",
       "      <th>10122</th>\n",
       "      <th>10123</th>\n",
       "      <th>10124</th>\n",
       "      <th>10125</th>\n",
       "      <th>10126</th>\n",
       "      <th>10127</th>\n",
       "      <th>10128</th>\n",
       "      <th>10129</th>\n",
       "      <th>10130</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(I, have, said, you, should, speak, presently, .)</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>austen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(And, I, see, very, few, pearls, in, the, room...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>chesterton</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(O, Cicero, ,, I, haue, seene, Tempests, ,, wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>whitman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(You, see, he, was, n't, well, enough, acquain...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>austen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(It, is, I, ,, you, women, ,, I, make, my, way...</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>whitman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BoW  Adv  Verb  Noun  Adj  \\\n",
       "0  (I, have, said, you, should, speak, presently, .)    1     4     0    0   \n",
       "1  (And, I, see, very, few, pearls, in, the, room...    1     1     3    1   \n",
       "2  (O, Cicero, ,, I, haue, seene, Tempests, ,, wh...    1     7     7    1   \n",
       "3  (You, see, he, was, n't, well, enough, acquain...    7     6     1    2   \n",
       "4  (It, is, I, ,, you, women, ,, I, make, my, way...    6    18     8    8   \n",
       "\n",
       "   Sent_len      author    0    1    2  ...    10121  10122  10123  10124  \\\n",
       "0         8      austen  0.0  0.0  0.0  ...      0.0    0.0    0.0    0.0   \n",
       "1        12  chesterton  0.0  0.0  0.0  ...      0.0    0.0    0.0    0.0   \n",
       "2        42     whitman  0.0  0.0  0.0  ...      0.0    0.0    0.0    0.0   \n",
       "3        29      austen  0.0  0.0  0.0  ...      0.0    0.0    0.0    0.0   \n",
       "4        87     whitman  0.0  0.0  0.0  ...      0.0    0.0    0.0    0.0   \n",
       "\n",
       "   10125  10126  10127  10128  10129  10130  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 10138 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay so I have the boW as features,\n",
    "# Now I want to obtain the tf-idf features too. \n",
    "X_norm_df = pd.DataFrame(data=X_norm.toarray())\n",
    "txt_tfidf_bow = pd.concat([txt_bow, X_norm_df], ignore_index=False, axis=1)\n",
    "txt_tfidf_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training dataframe shape: (27911, 10138)\n"
     ]
    }
   ],
   "source": [
    "print('Final training dataframe shape:', txt_tfidf_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying features and labels to choose from\n",
    "features = txt_tfidf_bow.drop(['BoW', 'author'], axis=1)\n",
    "y2_train = txt_tfidf_bow.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theres too many features at the moment, so I will limit it to top 150.\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Instantiating and fitting the 150 best features\n",
    "kbest = SelectKBest(chi2, k=150)\n",
    "X2_train = kbest.fit_transform(features, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "The point of using clusters is to group the paragraphs together to see if the clusters group accordingly to their author. There will be several different clustering techniques, the first being\n",
    "\n",
    "## K-Means Clustering\n",
    "\n",
    "K-means clustering is an iterative algorithm that seeks to cluster based on minimizing the inertia (cost function) or the sum of squared differences between the mean of the cluster and the data points of the cluster. \n",
    "\n",
    "Normally, the data would have to be normalized before using K-Means so that the distance would be accurate but that has already been done up top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>austen</th>\n",
       "      <td>271</td>\n",
       "      <td>1560</td>\n",
       "      <td>528</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1542</td>\n",
       "      <td>910</td>\n",
       "      <td>1319</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible</th>\n",
       "      <td>50</td>\n",
       "      <td>230</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>138</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bryant</th>\n",
       "      <td>101</td>\n",
       "      <td>528</td>\n",
       "      <td>164</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>514</td>\n",
       "      <td>289</td>\n",
       "      <td>427</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buster</th>\n",
       "      <td>33</td>\n",
       "      <td>179</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>116</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton</th>\n",
       "      <td>87</td>\n",
       "      <td>610</td>\n",
       "      <td>190</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>553</td>\n",
       "      <td>335</td>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgeworth</th>\n",
       "      <td>327</td>\n",
       "      <td>1892</td>\n",
       "      <td>727</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1900</td>\n",
       "      <td>1124</td>\n",
       "      <td>1535</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milton</th>\n",
       "      <td>93</td>\n",
       "      <td>504</td>\n",
       "      <td>175</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>546</td>\n",
       "      <td>306</td>\n",
       "      <td>402</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakes</th>\n",
       "      <td>51</td>\n",
       "      <td>375</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>210</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitman</th>\n",
       "      <td>152</td>\n",
       "      <td>1028</td>\n",
       "      <td>362</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1112</td>\n",
       "      <td>604</td>\n",
       "      <td>873</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         0     1    2   3  4     5     6     7  8    9\n",
       "author                                                     \n",
       "austen      271  1560  528  28  1  1542   910  1319  2  113\n",
       "bible        50   230   86  11  0   261   138   257  0   22\n",
       "bryant      101   528  164  14  2   514   289   427  3   41\n",
       "buster       33   179   60   6  0   203   116   156  0   11\n",
       "chesterton   87   610  190  12  0   553   335   493  0   32\n",
       "edgeworth   327  1892  727  45  3  1900  1124  1535  6  121\n",
       "milton       93   504  175   8  0   546   306   402  6   42\n",
       "shakes       51   375   98  10  0   372   210   292  1   17\n",
       "whitman     152  1028  362  20  0  1112   604   873  1   83"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# I will use 10 clusters because I have 10 authors.\n",
    "# Initialize the model. \n",
    "kmeans = KMeans(n_clusters=10, init='k-means++', random_state=42, n_init=20)\n",
    "\n",
    "# Fit and predict the model. \n",
    "y_pred = kmeans.fit_predict(X2_train)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: -0.0008466052\n",
      "Silhouette Score: 0.4815564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Evaluate the performance of the clusters\n",
    "\n",
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y2_train, y_pred)))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X2_train, y_pred, metric='euclidean')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted Rand Index is a function that measures the similarity of two assignments, ignoring permutations and with chance normalization. The score was negative which means that the similarity might as well be random. ARI has an accurate ground truth in the y-pred so it signals that the similarity isn't there.\n",
    "\n",
    "Silhouette Coefficient is the mean distance between a sample and all other points in the same class (a), the mean distance between a sample and all other points in the next nearest cluster (b), divided by whichever of the two values is highest. Scores around 0 indicate overlapping clusters. Score is higher when clusters are dense and well separated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a286c5b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "# Use the elbow method to see what is the optimal amount of clusters.\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,20)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X2_train)\n",
    "    kmeanModel.fit(X2_train)\n",
    "    distortions.append(sum(np.min(cdist(X2_train, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X2_train.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "sns.set_style('darkgrid')\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow is actually around 6 clusters but I have to use 10 in order to see if the models can label the 10 authors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch K Means \n",
    "\n",
    "Mini Batch won't really change much since it is only used when PCA isn't run to reduce dimensionality and search for clusters in the reduced data. Mini Batch is useful if I want to keep all the data and if I have limited computational power or time. It works by randomly sampling subsets of the training data in each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>austen</th>\n",
       "      <td>1332</td>\n",
       "      <td>384</td>\n",
       "      <td>27</td>\n",
       "      <td>958</td>\n",
       "      <td>85</td>\n",
       "      <td>1243</td>\n",
       "      <td>615</td>\n",
       "      <td>1446</td>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible</th>\n",
       "      <td>220</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>159</td>\n",
       "      <td>20</td>\n",
       "      <td>226</td>\n",
       "      <td>106</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bryant</th>\n",
       "      <td>446</td>\n",
       "      <td>120</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>31</td>\n",
       "      <td>404</td>\n",
       "      <td>193</td>\n",
       "      <td>479</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buster</th>\n",
       "      <td>177</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>6</td>\n",
       "      <td>163</td>\n",
       "      <td>73</td>\n",
       "      <td>160</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton</th>\n",
       "      <td>481</td>\n",
       "      <td>137</td>\n",
       "      <td>12</td>\n",
       "      <td>368</td>\n",
       "      <td>27</td>\n",
       "      <td>450</td>\n",
       "      <td>226</td>\n",
       "      <td>553</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgeworth</th>\n",
       "      <td>1648</td>\n",
       "      <td>513</td>\n",
       "      <td>46</td>\n",
       "      <td>1173</td>\n",
       "      <td>97</td>\n",
       "      <td>1436</td>\n",
       "      <td>804</td>\n",
       "      <td>1741</td>\n",
       "      <td>214</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milton</th>\n",
       "      <td>471</td>\n",
       "      <td>127</td>\n",
       "      <td>9</td>\n",
       "      <td>315</td>\n",
       "      <td>26</td>\n",
       "      <td>383</td>\n",
       "      <td>203</td>\n",
       "      <td>472</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakes</th>\n",
       "      <td>321</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>217</td>\n",
       "      <td>11</td>\n",
       "      <td>282</td>\n",
       "      <td>146</td>\n",
       "      <td>347</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitman</th>\n",
       "      <td>956</td>\n",
       "      <td>246</td>\n",
       "      <td>21</td>\n",
       "      <td>620</td>\n",
       "      <td>64</td>\n",
       "      <td>829</td>\n",
       "      <td>429</td>\n",
       "      <td>969</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          0    1   2     3   4     5    6     7    8  9\n",
       "author                                                      \n",
       "austen      1332  384  27   958  85  1243  615  1446  181  3\n",
       "bible        220   66  11   159  20   226  106   221   26  0\n",
       "bryant       446  120  14   321  31   404  193   479   71  4\n",
       "buster       177   39   6   113   6   163   73   160   27  0\n",
       "chesterton   481  137  12   368  27   450  226   553   58  0\n",
       "edgeworth   1648  513  46  1173  97  1436  804  1741  214  8\n",
       "milton       471  127   9   315  26   383  203   472   71  5\n",
       "shakes       321   54  11   217  11   282  146   347   37  0\n",
       "whitman      956  246  21   620  64   829  429   969  101  0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Initialize the model. \n",
    "minikmeans = MiniBatchKMeans(n_clusters=10, init='k-means++', random_state=42, init_size=1000, batch_size=1000)\n",
    "\n",
    "# Predict and fit the model. \n",
    "y_pred2 = minikmeans.fit_predict(X2_train)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: -0.0008780825\n",
      "Silhouette Score: 0.471433\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y2_train, y_pred2)))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X2_train, y_pred2, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did slightly worse than k-means but that is to be expected since this is just another rendition of the original k-means model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering\n",
    "\n",
    "Spectral Clustering is based on quantifying similarity between data points. Spectral clustering takes many different measures of similiarity. The two most common ones are nearest neighbor and the Gaussian kernel of the Euclidean distance. I will put in 10 clusters and the 10 eigenvectors with the 10 largest eigenvalues are extracted and the data is converted to the new 10 dimensional space. This will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import SpectralClustering\n",
    "# # Pick the number of clusters.\n",
    "# n_clusters= 10\n",
    "\n",
    "# # Initialize the model.\n",
    "# sc = SpectralClustering(n_clusters=n_clusters)\n",
    "\n",
    "# # Fit and predict the model.\n",
    "# y_pred3 = sc.fit_predict(X2_train)\n",
    "\n",
    "# pd.crosstab(y2_train, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would've shown the results the spectral clustering model but it took 11 hours and the program was still running. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n",
      "               Adv         Verb         Noun          Adj     Sent_len  \\\n",
      "count  5598.000000  5598.000000  5598.000000  5598.000000  5598.000000   \n",
      "mean      1.552519     4.051447     3.297785     2.041979    23.427117   \n",
      "std       1.324988     1.649640     1.705732     1.468089     3.084127   \n",
      "min       0.000000     0.000000     0.000000     0.000000    18.000000   \n",
      "25%       1.000000     3.000000     2.000000     1.000000    21.000000   \n",
      "50%       1.000000     4.000000     3.000000     2.000000    23.000000   \n",
      "75%       2.000000     5.000000     4.000000     3.000000    26.000000   \n",
      "max       8.000000    11.000000    11.000000     9.000000    30.000000   \n",
      "\n",
      "                 0            1            2            3            4  \\\n",
      "count  5598.000000  5598.000000  5598.000000  5598.000000  5598.000000   \n",
      "mean      0.001332     0.000769     0.000861     0.000681     0.001070   \n",
      "std       0.031223     0.023201     0.026685     0.022140     0.028999   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              ...                10122        10123        10124        10125  \\\n",
      "count         ...          5598.000000  5598.000000  5598.000000  5598.000000   \n",
      "mean          ...             0.000281     0.000202     0.000083     0.000478   \n",
      "std           ...             0.008903     0.008705     0.006174     0.012436   \n",
      "min           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "25%           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "50%           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "75%           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "max           ...             0.408495     0.383911     0.461926     0.475857   \n",
      "\n",
      "             10126        10127        10128   10129   10130  \\\n",
      "count  5598.000000  5598.000000  5598.000000  5598.0  5598.0   \n",
      "mean      0.000058     0.000294     0.000106     0.0     0.0   \n",
      "std       0.004368     0.012940     0.005652     0.0     0.0   \n",
      "min       0.000000     0.000000     0.000000     0.0     0.0   \n",
      "25%       0.000000     0.000000     0.000000     0.0     0.0   \n",
      "50%       0.000000     0.000000     0.000000     0.0     0.0   \n",
      "75%       0.000000     0.000000     0.000000     0.0     0.0   \n",
      "max       0.326820     0.682886     0.322706     0.0     0.0   \n",
      "\n",
      "       cluster_assignment  \n",
      "count              5598.0  \n",
      "mean                  0.0  \n",
      "std                   0.0  \n",
      "min                   0.0  \n",
      "25%                   0.0  \n",
      "50%                   0.0  \n",
      "75%                   0.0  \n",
      "max                   0.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "1\n",
      "\n",
      "\n",
      "              Adv        Verb        Noun         Adj    Sent_len           0  \\\n",
      "count  365.000000  365.000000  365.000000  365.000000  365.000000  365.000000   \n",
      "mean     5.712329   14.197260   17.706849   10.567123   99.816438    0.001879   \n",
      "std      3.346638    4.900605    5.605049    4.185797   10.744114    0.035893   \n",
      "min      0.000000    2.000000    3.000000    0.000000   84.000000    0.000000   \n",
      "25%      3.000000   11.000000   13.000000    7.000000   90.000000    0.000000   \n",
      "50%      5.000000   14.000000   17.000000   10.000000   98.000000    0.000000   \n",
      "75%      8.000000   18.000000   21.000000   13.000000  107.000000    0.000000   \n",
      "max     19.000000   28.000000   36.000000   24.000000  125.000000    0.685733   \n",
      "\n",
      "           1      2      3           4         ...          10122  10123  \\\n",
      "count  365.0  365.0  365.0  365.000000         ...          365.0  365.0   \n",
      "mean     0.0    0.0    0.0    0.000760         ...            0.0    0.0   \n",
      "std      0.0    0.0    0.0    0.014511         ...            0.0    0.0   \n",
      "min      0.0    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "25%      0.0    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "50%      0.0    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "75%      0.0    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "max      0.0    0.0    0.0    0.277234         ...            0.0    0.0   \n",
      "\n",
      "       10124  10125  10126  10127  10128  10129  10130  cluster_assignment  \n",
      "count  365.0  365.0  365.0  365.0  365.0  365.0  365.0               365.0  \n",
      "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0                 1.0  \n",
      "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 0.0  \n",
      "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 1.0  \n",
      "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 1.0  \n",
      "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 1.0  \n",
      "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 1.0  \n",
      "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 1.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "2\n",
      "\n",
      "\n",
      "               Adv         Verb         Noun          Adj     Sent_len  \\\n",
      "count  7948.000000  7948.000000  7948.000000  7948.000000  7948.000000   \n",
      "mean      0.358078     0.859084     0.661802     0.356694     5.180045   \n",
      "std       0.621428     0.896154     0.781931     0.605101     2.605503   \n",
      "min       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     3.000000   \n",
      "50%       0.000000     1.000000     0.000000     0.000000     5.000000   \n",
      "75%       1.000000     1.000000     1.000000     1.000000     7.000000   \n",
      "max       4.000000     5.000000     5.000000     4.000000    10.000000   \n",
      "\n",
      "                 0            1            2            3            4  \\\n",
      "count  7948.000000  7948.000000  7948.000000  7948.000000  7948.000000   \n",
      "mean      0.000518     0.001294     0.001068     0.000487     0.000833   \n",
      "std       0.018881     0.033744     0.027819     0.017354     0.027547   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     0.730758     1.000000   \n",
      "\n",
      "              ...                10122        10123        10124        10125  \\\n",
      "count         ...          7948.000000  7948.000000  7948.000000  7948.000000   \n",
      "mean          ...             0.000459     0.000155     0.000071     0.000501   \n",
      "std           ...             0.015468     0.007014     0.006325     0.013397   \n",
      "min           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "25%           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "50%           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "75%           ...             0.000000     0.000000     0.000000     0.000000   \n",
      "max           ...             0.795040     0.393890     0.563865     0.534573   \n",
      "\n",
      "             10126   10127        10128        10129   10130  \\\n",
      "count  7948.000000  7948.0  7948.000000  7948.000000  7948.0   \n",
      "mean      0.000086     0.0     0.000058     0.000027     0.0   \n",
      "std       0.005473     0.0     0.003920     0.002368     0.0   \n",
      "min       0.000000     0.0     0.000000     0.000000     0.0   \n",
      "25%       0.000000     0.0     0.000000     0.000000     0.0   \n",
      "50%       0.000000     0.0     0.000000     0.000000     0.0   \n",
      "75%       0.000000     0.0     0.000000     0.000000     0.0   \n",
      "max       0.391941     0.0     0.317339     0.211131     0.0   \n",
      "\n",
      "       cluster_assignment  \n",
      "count              7948.0  \n",
      "mean                  2.0  \n",
      "std                   0.0  \n",
      "min                   2.0  \n",
      "25%                   2.0  \n",
      "50%                   2.0  \n",
      "75%                   2.0  \n",
      "max                   2.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "3\n",
      "\n",
      "\n",
      "               Adv         Verb         Noun          Adj     Sent_len  \\\n",
      "count  3573.000000  3573.000000  3573.000000  3573.000000  3573.000000   \n",
      "mean      2.220823     5.766303     5.318780     3.245732    34.966975   \n",
      "std       1.643881     2.137744     2.302192     1.868002     3.777034   \n",
      "min       0.000000     0.000000     0.000000     0.000000    29.000000   \n",
      "25%       1.000000     4.000000     4.000000     2.000000    32.000000   \n",
      "50%       2.000000     6.000000     5.000000     3.000000    35.000000   \n",
      "75%       3.000000     7.000000     7.000000     4.000000    38.000000   \n",
      "max      11.000000    14.000000    15.000000    13.000000    43.000000   \n",
      "\n",
      "                 0            1            2            3            4  \\\n",
      "count  3573.000000  3573.000000  3573.000000  3573.000000  3573.000000   \n",
      "mean      0.001036     0.000439     0.000809     0.001305     0.000835   \n",
      "std       0.031241     0.018153     0.021030     0.033750     0.023554   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     0.714598     1.000000     0.703622   \n",
      "\n",
      "              ...           10122   10123   10124        10125        10126  \\\n",
      "count         ...          3573.0  3573.0  3573.0  3573.000000  3573.000000   \n",
      "mean          ...             0.0     0.0     0.0     0.000312     0.000081   \n",
      "std           ...             0.0     0.0     0.0     0.010036     0.004849   \n",
      "min           ...             0.0     0.0     0.0     0.000000     0.000000   \n",
      "25%           ...             0.0     0.0     0.0     0.000000     0.000000   \n",
      "50%           ...             0.0     0.0     0.0     0.000000     0.000000   \n",
      "75%           ...             0.0     0.0     0.0     0.000000     0.000000   \n",
      "max           ...             0.0     0.0     0.0     0.494852     0.289830   \n",
      "\n",
      "        10127        10128        10129        10130  cluster_assignment  \n",
      "count  3573.0  3573.000000  3573.000000  3573.000000              3573.0  \n",
      "mean      0.0     0.000078     0.000060     0.000070                 3.0  \n",
      "std       0.0     0.004656     0.003557     0.004197                 0.0  \n",
      "min       0.0     0.000000     0.000000     0.000000                 3.0  \n",
      "25%       0.0     0.000000     0.000000     0.000000                 3.0  \n",
      "50%       0.0     0.000000     0.000000     0.000000                 3.0  \n",
      "75%       0.0     0.000000     0.000000     0.000000                 3.0  \n",
      "max       0.0     0.278292     0.212628     0.250862                 3.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Adv         Verb         Noun          Adj     Sent_len  \\\n",
      "count  1939.000000  1939.000000  1939.000000  1939.000000  1939.000000   \n",
      "mean      3.153172     8.051057     7.849407     4.832904    49.802476   \n",
      "std       2.051392     2.835346     3.007904     2.372645     4.963403   \n",
      "min       0.000000     0.000000     0.000000     0.000000    42.000000   \n",
      "25%       2.000000     6.000000     6.000000     3.000000    45.000000   \n",
      "50%       3.000000     8.000000     8.000000     5.000000    49.000000   \n",
      "75%       4.000000    10.000000    10.000000     6.000000    54.000000   \n",
      "max      11.000000    18.000000    19.000000    14.000000    61.000000   \n",
      "\n",
      "                 0            1            2            3            4  \\\n",
      "count  1939.000000  1939.000000  1939.000000  1939.000000  1939.000000   \n",
      "mean      0.002158     0.000860     0.000403     0.000440     0.001450   \n",
      "std       0.041640     0.023208     0.013783     0.016581     0.031911   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     0.700727     0.568291     0.717325     0.713430   \n",
      "\n",
      "              ...                10122   10123   10124        10125   10126  \\\n",
      "count         ...          1939.000000  1939.0  1939.0  1939.000000  1939.0   \n",
      "mean          ...             0.000136     0.0     0.0     0.000221     0.0   \n",
      "std           ...             0.005975     0.0     0.0     0.009731     0.0   \n",
      "min           ...             0.000000     0.0     0.0     0.000000     0.0   \n",
      "25%           ...             0.000000     0.0     0.0     0.000000     0.0   \n",
      "50%           ...             0.000000     0.0     0.0     0.000000     0.0   \n",
      "75%           ...             0.000000     0.0     0.0     0.000000     0.0   \n",
      "max           ...             0.263118     0.0     0.0     0.428508     0.0   \n",
      "\n",
      "             10127        10128   10129   10130  cluster_assignment  \n",
      "count  1939.000000  1939.000000  1939.0  1939.0              1939.0  \n",
      "mean      0.000172     0.000492     0.0     0.0                 4.0  \n",
      "std       0.007553     0.013168     0.0     0.0                 0.0  \n",
      "min       0.000000     0.000000     0.0     0.0                 4.0  \n",
      "25%       0.000000     0.000000     0.0     0.0                 4.0  \n",
      "50%       0.000000     0.000000     0.0     0.0                 4.0  \n",
      "75%       0.000000     0.000000     0.0     0.0                 4.0  \n",
      "max       0.332607     0.464733     0.0     0.0                 4.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "5\n",
      "\n",
      "\n",
      "             Adv       Verb        Noun        Adj    Sent_len    0    1    2  \\\n",
      "count   6.000000   6.000000    6.000000   6.000000    6.000000  6.0  6.0  6.0   \n",
      "mean   18.333333  39.666667  144.666667  45.833333  507.500000  0.0  0.0  0.0   \n",
      "std    10.112698  11.290114   28.225284  16.375795   80.852335  0.0  0.0  0.0   \n",
      "min     3.000000  26.000000  116.000000  25.000000  412.000000  0.0  0.0  0.0   \n",
      "25%    12.250000  32.750000  122.000000  35.750000  441.500000  0.0  0.0  0.0   \n",
      "50%    20.500000  38.500000  139.500000  43.000000  508.000000  0.0  0.0  0.0   \n",
      "75%    25.750000  44.250000  162.250000  58.500000  570.750000  0.0  0.0  0.0   \n",
      "max    29.000000  58.000000  187.000000  67.000000  606.000000  0.0  0.0  0.0   \n",
      "\n",
      "         3    4         ...          10122  10123  10124  10125  10126  10127  \\\n",
      "count  6.0  6.0         ...            6.0    6.0    6.0    6.0    6.0    6.0   \n",
      "mean   0.0  0.0         ...            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "std    0.0  0.0         ...            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "min    0.0  0.0         ...            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "25%    0.0  0.0         ...            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "50%    0.0  0.0         ...            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "75%    0.0  0.0         ...            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "max    0.0  0.0         ...            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "       10128  10129  10130  cluster_assignment  \n",
      "count    6.0    6.0    6.0                 6.0  \n",
      "mean     0.0    0.0    0.0                 5.0  \n",
      "std      0.0    0.0    0.0                 0.0  \n",
      "min      0.0    0.0    0.0                 5.0  \n",
      "25%      0.0    0.0    0.0                 5.0  \n",
      "50%      0.0    0.0    0.0                 5.0  \n",
      "75%      0.0    0.0    0.0                 5.0  \n",
      "max      0.0    0.0    0.0                 5.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "6\n",
      "\n",
      "\n",
      "              Adv        Verb        Noun         Adj    Sent_len      0  \\\n",
      "count  140.000000  140.000000  140.000000  140.000000  140.000000  140.0   \n",
      "mean     7.742857   18.242857   30.514286   14.785714  149.428571    0.0   \n",
      "std      4.624569    7.679620    9.229672    4.889845   17.416251    0.0   \n",
      "min      0.000000    2.000000    8.000000    2.000000  124.000000    0.0   \n",
      "25%      5.000000   12.000000   23.000000   11.000000  135.000000    0.0   \n",
      "50%      7.000000   18.500000   30.000000   14.000000  147.000000    0.0   \n",
      "75%     10.000000   22.250000   36.000000   18.000000  161.250000    0.0   \n",
      "max     26.000000   42.000000   56.000000   29.000000  197.000000    0.0   \n",
      "\n",
      "                1      2      3           4         ...          10122  10123  \\\n",
      "count  140.000000  140.0  140.0  140.000000         ...          140.0  140.0   \n",
      "mean     0.002852    0.0    0.0    0.008788         ...            0.0    0.0   \n",
      "std      0.033750    0.0    0.0    0.086591         ...            0.0    0.0   \n",
      "min      0.000000    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "25%      0.000000    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "50%      0.000000    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "75%      0.000000    0.0    0.0    0.000000         ...            0.0    0.0   \n",
      "max      0.399338    0.0    0.0    1.000000         ...            0.0    0.0   \n",
      "\n",
      "       10124  10125  10126  10127  10128  10129  10130  cluster_assignment  \n",
      "count  140.0  140.0  140.0  140.0  140.0  140.0  140.0               140.0  \n",
      "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0                 6.0  \n",
      "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 0.0  \n",
      "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 6.0  \n",
      "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 6.0  \n",
      "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 6.0  \n",
      "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 6.0  \n",
      "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0                 6.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "7\n",
      "\n",
      "\n",
      "              Adv        Verb        Noun         Adj    Sent_len           0  \\\n",
      "count  869.000000  869.000000  869.000000  869.000000  869.000000  869.000000   \n",
      "mean     4.360184   10.771001   11.714614    7.196778   70.209436    0.001605   \n",
      "std      2.523681    3.702258    4.086792    3.061834    7.096917    0.033445   \n",
      "min      0.000000    0.000000    0.000000    0.000000   59.000000    0.000000   \n",
      "25%      3.000000    8.000000    9.000000    5.000000   64.000000    0.000000   \n",
      "50%      4.000000   11.000000   11.000000    7.000000   69.000000    0.000000   \n",
      "75%      6.000000   13.000000   14.000000    9.000000   76.000000    0.000000   \n",
      "max     16.000000   23.000000   29.000000   19.000000   86.000000    0.698050   \n",
      "\n",
      "                1           2      3           4         ...          \\\n",
      "count  869.000000  869.000000  869.0  869.000000         ...           \n",
      "mean     0.000802    0.001866    0.0    0.000811         ...           \n",
      "std      0.023651    0.034836    0.0    0.023899         ...           \n",
      "min      0.000000    0.000000    0.0    0.000000         ...           \n",
      "25%      0.000000    0.000000    0.0    0.000000         ...           \n",
      "50%      0.000000    0.000000    0.0    0.000000         ...           \n",
      "75%      0.000000    0.000000    0.0    0.000000         ...           \n",
      "max      0.697211    0.716866    0.0    0.704516         ...           \n",
      "\n",
      "            10122       10123  10124  10125  10126  10127  10128       10129  \\\n",
      "count  869.000000  869.000000  869.0  869.0  869.0  869.0  869.0  869.000000   \n",
      "mean     0.000160    0.000394    0.0    0.0    0.0    0.0    0.0    0.000233   \n",
      "std      0.004703    0.011603    0.0    0.0    0.0    0.0    0.0    0.006854   \n",
      "min      0.000000    0.000000    0.0    0.0    0.0    0.0    0.0    0.000000   \n",
      "25%      0.000000    0.000000    0.0    0.0    0.0    0.0    0.0    0.000000   \n",
      "50%      0.000000    0.000000    0.0    0.0    0.0    0.0    0.0    0.000000   \n",
      "75%      0.000000    0.000000    0.0    0.0    0.0    0.0    0.0    0.000000   \n",
      "max      0.138636    0.342051    0.0    0.0    0.0    0.0    0.0    0.202047   \n",
      "\n",
      "       10130  cluster_assignment  \n",
      "count  869.0               869.0  \n",
      "mean     0.0                 7.0  \n",
      "std      0.0                 0.0  \n",
      "min      0.0                 7.0  \n",
      "25%      0.0                 7.0  \n",
      "50%      0.0                 7.0  \n",
      "75%      0.0                 7.0  \n",
      "max      0.0                 7.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Adv       Verb        Noun        Adj    Sent_len     0     1  \\\n",
      "count  19.000000  19.000000   19.000000  19.000000   19.000000  19.0  19.0   \n",
      "mean   11.578947  30.842105   58.157895  25.210526  254.210526   0.0   0.0   \n",
      "std     6.431829   8.989272   17.445990   6.948852   43.471036   0.0   0.0   \n",
      "min     1.000000  19.000000   37.000000  16.000000  201.000000   0.0   0.0   \n",
      "25%     6.500000  23.000000   44.500000  20.000000  226.500000   0.0   0.0   \n",
      "50%    11.000000  32.000000   57.000000  24.000000  243.000000   0.0   0.0   \n",
      "75%    15.000000  35.500000   64.500000  29.000000  268.500000   0.0   0.0   \n",
      "max    28.000000  48.000000  103.000000  38.000000  361.000000   0.0   0.0   \n",
      "\n",
      "          2     3     4         ...          10122  10123  10124  10125  \\\n",
      "count  19.0  19.0  19.0         ...           19.0   19.0   19.0   19.0   \n",
      "mean    0.0   0.0   0.0         ...            0.0    0.0    0.0    0.0   \n",
      "std     0.0   0.0   0.0         ...            0.0    0.0    0.0    0.0   \n",
      "min     0.0   0.0   0.0         ...            0.0    0.0    0.0    0.0   \n",
      "25%     0.0   0.0   0.0         ...            0.0    0.0    0.0    0.0   \n",
      "50%     0.0   0.0   0.0         ...            0.0    0.0    0.0    0.0   \n",
      "75%     0.0   0.0   0.0         ...            0.0    0.0    0.0    0.0   \n",
      "max     0.0   0.0   0.0         ...            0.0    0.0    0.0    0.0   \n",
      "\n",
      "       10126  10127  10128  10129  10130  cluster_assignment  \n",
      "count   19.0   19.0   19.0   19.0   19.0                19.0  \n",
      "mean     0.0    0.0    0.0    0.0    0.0                 8.0  \n",
      "std      0.0    0.0    0.0    0.0    0.0                 0.0  \n",
      "min      0.0    0.0    0.0    0.0    0.0                 8.0  \n",
      "25%      0.0    0.0    0.0    0.0    0.0                 8.0  \n",
      "50%      0.0    0.0    0.0    0.0    0.0                 8.0  \n",
      "75%      0.0    0.0    0.0    0.0    0.0                 8.0  \n",
      "max      0.0    0.0    0.0    0.0    0.0                 8.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n",
      "9\n",
      "\n",
      "\n",
      "              Adv         Verb         Noun          Adj     Sent_len  \\\n",
      "count  7454.00000  7454.000000  7454.000000  7454.000000  7454.000000   \n",
      "mean      0.97773     2.466461     1.815938     1.127314    13.743225   \n",
      "std       1.01209     1.242885     1.252367     1.055051     2.603256   \n",
      "min       0.00000     0.000000     0.000000     0.000000    10.000000   \n",
      "25%       0.00000     2.000000     1.000000     0.000000    11.000000   \n",
      "50%       1.00000     2.000000     2.000000     1.000000    14.000000   \n",
      "75%       2.00000     3.000000     3.000000     2.000000    16.000000   \n",
      "max       6.00000     8.000000     8.000000     7.000000    19.000000   \n",
      "\n",
      "                 0            1            2            3            4  \\\n",
      "count  7454.000000  7454.000000  7454.000000  7454.000000  7454.000000   \n",
      "mean      0.001208     0.001066     0.001257     0.001253     0.000974   \n",
      "std       0.031880     0.027298     0.032554     0.032040     0.027252   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              ...                10122        10123   10124        10125  \\\n",
      "count         ...          7454.000000  7454.000000  7454.0  7454.000000   \n",
      "mean          ...             0.000178     0.000038     0.0     0.000319   \n",
      "std           ...             0.006570     0.003313     0.0     0.008226   \n",
      "min           ...             0.000000     0.000000     0.0     0.000000   \n",
      "25%           ...             0.000000     0.000000     0.0     0.000000   \n",
      "50%           ...             0.000000     0.000000     0.0     0.000000   \n",
      "75%           ...             0.000000     0.000000     0.0     0.000000   \n",
      "max           ...             0.283020     0.286013     0.0     0.322168   \n",
      "\n",
      "             10126        10127        10128        10129        10130  \\\n",
      "count  7454.000000  7454.000000  7454.000000  7454.000000  7454.000000   \n",
      "mean      0.000026     0.000158     0.000021     0.000043     0.000049   \n",
      "std       0.002247     0.008519     0.001797     0.003688     0.004260   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       0.193998     0.612711     0.155163     0.318409     0.367800   \n",
      "\n",
      "       cluster_assignment  \n",
      "count              7454.0  \n",
      "mean                  9.0  \n",
      "std                   0.0  \n",
      "min                   9.0  \n",
      "25%                   9.0  \n",
      "50%                   9.0  \n",
      "75%                   9.0  \n",
      "max                   9.0  \n",
      "\n",
      "[8 rows x 10137 columns]\n"
     ]
    }
   ],
   "source": [
    "cluster_pred = KMeans(n_clusters=10, random_state=42).fit_predict(features)\n",
    "X_pred = features.copy()\n",
    "X_pred['cluster_assignment'] = cluster_pred\n",
    "\n",
    "cluster_dataframes = {}\n",
    "for n_clust in range(10):\n",
    "    cluster_dataframes[n_clust] = X_pred.loc[X_pred['cluster_assignment'] == n_clust]\n",
    "\n",
    "for name, frame in cluster_dataframes.items():\n",
    "    print(name)\n",
    "    print('\\n')\n",
    "    print(frame.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a problem. For the clusters I don't know what word is what word. To properly show the information of the clusters I will only use the part of speeches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis\n",
    "\n",
    "Previously, my data set had a lot of data in it. I decided in order to remedy this by running the LSA which is a dimension reduction technique (PCA) on the tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 99.83034394754688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 27911 to 10.\n",
    "svd= TruncatedSVD(10)\n",
    "\n",
    "# Train the data for features since there's non tf-idf data in the features section.\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(features)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It captured a lot of the variance of the data, perhaps too much. Lets check the sentence similarity. \n",
    "\n",
    "## Sentence Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD3CAYAAAAua/5EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHrVJREFUeJzt3X9UVGX+B/D3zACDMij+CMuUEQnI2oSFE2smJgS1ubWW2AEibFPJ1LJtaUVEEYlAOmttav6gTS1KI7XaVju5uf5Acd2EFb+yJ2e/Iv1AOWbBrgwiA3Of7x+eZr/aJjPOvZc73ffLc89x7pX7vhp9fPzc597HIIQQICIizTD29QUQEdHlWJiJiDSGhZmISGNYmImINIaFmYhIY1iYiYg0hoWZiMhDx44dQ3Z29vf279mzB2lpaUhPT8e7774LALh48SKefvppPPLII8jJyUFra2uv52dhJiLywGuvvYbFixejq6vrsv3d3d0oKyvDhg0bUFlZiaqqKpw7dw5btmxBVFQUNm/ejAcffBBr1qzpNYOFmYjIA2FhYVi1atX39jc2NiIsLAwDBw5EQEAA4uPjUVtbi7q6OiQmJgIAJk6ciL/+9a+9ZvjJftXXoPubU6rk9BueqEoOAGwamqRaVpL1jCo5BoN6D4lO+t921bKe6Hezaln9VfojlNSJAQD86tFOFdMAS9l2r77ek3rjP3T09/bde++9aG5u/t5+u92O4OBg1+egoCDY7fbL9gcFBaG9vffvbU0UZiIi1UhORU5rsVjQ0dHh+tzR0YHg4ODL9nd0dGDAgAG9noutDCLSFyG5v3kgIiICX3zxBf71r3/B4XCgtrYWP/3pTxEXF4f9+/cDAKqrqxEfH9/ruThiJiJ9keRt9PzpT3/ChQsXkJ6ejoULF2LmzJkQQiAtLQ3Dhg1DZmYm8vLykJmZCX9/f6xYsaLXcxq08HY59pi9wx6zd9hj9o6v9ZgdZ/7h9q8NGH6rV1nXiiNmItIXZ09fX0GvWJiJSF8UuvknJxZmItIXD2/q9QUWZiLSF5lv/ilB0cIsSRKMRs7IIyLtEHocMX/11VcoKytDQ0MD/Pz8IEkSoqKikJ+fj/DwcLnjiIg8o8cRc0FBAXJzcxETE+PaV19fj/z8fLzzzjtyxxERecbZ3ddX0CvZC7PD4bisKANAbGys3DFERNdGj62M6Oho5OfnIzExEcHBwejo6MD+/fsRHR0tdxQRkef02MooKirC7t27UVdXB7vdDovFgqSkJKSmpsodRUTkOT2OmA0GA1JTU1mIiUib9DhiJiLSMiHp8OYfEZGmccRMRKQxeuwxExFpGl9iRESkMRwxu0etF9h3njmgSg4AOE8eUS2rfUnvy6HLwfLYBFVyAKBhwkOqZQl7m2pZ8AtQJ8doUicHgHPXZtWyZMEeMxGRxvBF+UREGsMRMxGRtgjBm39ERNrCETMRkcZwVgYRkcZwxExEpDGclUFEpDFsZRARaQxbGUREGsPCTESkMXpsZWRnZ6O7+/IXUQshYDAYuEo2EfU9Pd78e+6557B48WK8+uqrMJnUe5EKEZFb9NjKiImJwZQpU2Cz2bjuHxFpjx5bGQAwa9YsJU5LROQ9PY6YiYg0jYWZiEhjhOjrK+gVCzMR6UuPDmdlEBFpmhc3/yRJQlFREWw2GwICAlBSUgKr1eo6XlFRgZ07d8JisWDWrFlISkrCmTNnsGDBAgghMHDgQKxYsQL9+vW7ao7xmq+QiMgXSZL72xV2794Nh8OBqqoq5ObmYvny5a5jNpsNO3bswLvvvosNGzZg5cqV6OzsxKZNm3Dffffh7bffRmRkJLZt29brJbIwE5G+COH+doW6ujokJl5aPDo2NhYNDQ2uY42NjUhISIDZbIbZbIbVaoXNZsOYMWNw/vx5AIDdboefX++NCk20MjYNTVIlR82Vq0033a5aVmB0kCo5xthJquQAgPPz/1EtyzjyFtWy1GLoF6xaljFxsmpZsvBiVobdbofFYnF9NplM6OnpgZ+fH6Kjo1FRUQG73Y7u7m4cPXoU6enpuP7667FixQrs2LEDDocDTz31VK85mijMRESq8aIwWywWdHR0/L9TSa4RcEREBLKyspCTkwOr1YqYmBgMGjQI+fn5KCsrQ2JiIvbt24e8vDxUVFRcNYetDCLSFeF0ur1dKS4uDtXV1QCA+vp6REVFuY61traira0NW7ZsQUFBAVpaWhAZGYkBAwYgOPjSv2BCQ0NdbY2r4YiZiPTFixFzamoqampqkJGRASEESktLsXHjRoSFhSE5ORnNzc1IS0uDv78/FixYAJPJhCVLlqC4uBiSJEEIgcLCwl5zWJiJSF+8mC5nNBpRXFx82b6IiAjXz688BgA33XQT3nzzTY9yWJiJSF8kPvlHRKQtfFcGEZHG/JebelrDwkxE+sIR8yUOhwMBAQFqRBERXZ0P9Jhlnce8Z88eJCUlITU1FR999JFrP1+cT0SaIST3tz4i64h53bp1eP/99yGEwDPPPIOuri489NBDED7w/lMi0gkfGDHLWpj9/f0REhICAFizZg0ee+wx3HDDDTAYDHLGEBFdM+EDPWZZWxk33ngjysrKcOHCBVgsFqxevRrFxcU4deqUnDFERNfO6XR/6yOyFubS0lJER0e7Rsg33HAD3nzzTdx3331yxhARXTtJuL/1EVlbGX5+fpg6depl+4YOHYqCggI5Y4iIrp0PtDI4j5mI9EVvN/+IiDSvD6fBuYuFmYj0hSNmIiJtET18VwYRkbZwxExEpDHsMbsnyXpGlZz2JWtUyQHUW7kaAAKLVquS03PoPVVyAMBZc0i1LGnAPtWy0OVQJcYwJESVHAAw3DBctSwAQOz93n09R8xERNoiWJiJiDSGN/+IiDSGI2YiIo1hYSYi0hZfeD88CzMR6QtHzEREGsPCTESkLaKHD5jg4sWLMBqNXCWbiLRB+3VZ3hVMAOCrr77C3LlzUVhYiEOHDmHy5MmYPHky9u7dK3cUEZHHhCTc3vqK7CPmRYsW4emnn8bp06cxf/587Nq1C2azGbNmzUJSUpLccUREntFjj7mnpwcJCQkAgL/97W8YMmTIpSA/trOJSAP02MoIDw9HQUEBJEnC8uXLAQAVFRUYOnSo3FFERB7TZSujpKQEe/bsgdH4n5o/bNgwZGdnyx1FROQx0aPDVobRaERKSspl+6ZMmSJ3DBHRtfGBVgYbv0SkKz7wnnwWZiLSGRZmIiJt8WbELEkSioqKYLPZEBAQgJKSElitVtfxiooK7Ny5ExaLxTVF+MKFCygqKkJzczO6u7uxZMkSjB079qo5LMxEpCui59q/dvfu3XA4HKiqqkJ9fT2WL1+OtWvXAgBsNht27NiBrVu3AgAyMjIwbtw4vP7664iMjMSLL76IEydO4MSJE70WZtmnyxERaZmQ3N+uVFdXh8TERABAbGwsGhoaXMcaGxuRkJAAs9kMs9kMq9UKm82GgwcPwt/fHzNnzsSaNWtcX381mhgxGwzqTF+xPDZBlRwAMMZOUi1LrUVS/cZPVSUHADBgsHpZKt4NMvQLVidnYKgqOQCAgH7qZcnAm//cdrsdFovF9dlkMqGnpwd+fn6Ijo5GRUUF7HY7uru7cfToUaSnp6OtrQ3nz5/H66+/jg8++ADl5eV48cUXr5qjicJMRKQaYbjmL7VYLOjo6HB9liTJ9VRzREQEsrKykJOTA6vVipiYGAwaNAghISFITk4GACQlJaGioqLXHLYyiEhXvGllxMXFobq6GgBQX1+PqKgo17HW1la0tbVhy5YtKCgoQEtLCyIjIxEfH4/9+/cDAI4cOYKbbrqp12vkiJmIdEVI1z5iTk1NRU1NDTIyMiCEQGlpKTZu3IiwsDAkJyejubkZaWlp8Pf3x4IFC2AymTB79mwsXrwY6enp8PPzQ3l5ea85LMxEpCuS89oLs9FoRHFx8WX7IiIiXD+/8hgAhISEYPXq1R7lsDATka7wyT8iIo3xppWhFhZmItIVof2Xy7EwE5G+cMRMRKQx3tz8U4ui85i//fZbJU9PROQxIRnc3vqKrCPmpqamyz7n5eW55uyFh4fLGUVEdE2EF0/+qUXWwvz4448jMDAQoaGhEEKgqakJhYWFMBgMePPNN+WMIiK6JrqbLrd9+3YsXboUmZmZuPPOO5GdnY3Kyko5I4iIvCLpbcQ8ZMgQ/P73v0d5eTmOHz8u56mJiGThC60M2W/++fn5oaCgwNXOICLSEslpcHvrK4pNl5s6dSqmTlXx/b1ERG7whXnMvY6Ye3ouX4fl/Pnzil0MEZHSJGFwe+srP1iYz507h6amJjzyyCP4/PPP0dTUhMbGRsyYMUPN6yMikpUQBre3vvKDrYxjx47hjTfecE15E0LAaDRiwgT1lmciIpKbL9z6+sHCnJKSgpSUFPzlL3/B3Xff7dpvt9tVuTAiIiX4wnS5XnvMGzduxNdffw3g0ig6IyND8YsiIlKKJBnc3vpKr7My5s2bhyeeeAK33347Ghoa8Morr8h+EZP+t132c/43DRMeUiUHAJyf/496WTWH1AlSceVqv59MUi2rp2GfalnwN6uXpRKpWp1V2l0ixnn15T+KEXNkZCSGDBmCQ4cOYezYsQgLC1PjuoiIFOELN/96LcxZWVnIzMzEzp07ERoaivT0dDWui4hIEb4wXa7XVsYbb7yB66+/HgAwc+ZM/OxnP1P8ooiIlOIDkzJ6L8zt7e34zW9+g/b2djzwwAOIjIxU47qIiBThlBR9Db0ser3CkpISlJWVISQkBNOmTcOqVavUuC4iIkVIHmx9xa13ZVitVhgMBgwePBhBQUFKXxMRkWIEtD8ro9fCPHDgQLzzzjvo7OzEzp07MXDgQDWui4hIEZIPNJl7LcxRUVE4ffo0Bg8ejIaGBgwerN5cViIiuUm+PGLeunUrtm3bhsbGRkRERAAAamtrv/e2uauRJAnnzp3DddddB6NR+w13Ivrx8+lWxpQpU3DHHXdg/fr1ePLJJwEARqMRQ4YMueoJFy1ahNLSUhw7dgzPPfccQkJC0NHRgdLSUsTGxsp79UREHnL6cmEOCAjAiBEj8Pzzz3t0wubmZgDAyy+/jNdeew2jRo3C2bNnkZubi7feesu7qyUi8pIPrMWq3AomJpMJo0aNAgAMGzYMkuQLfxxE9GPnC5VI9sZve3s7pk6ditOnT2Pr1q3o6urCsmXLMHz4cLmjiIg8JmBwe+srso+Y33//fTgcDpw4cQKBgYEwGAyIiorCtGnT5I4iIvKYDyz5p0wrIyAgAGPHjnV9zszMVCKGiMhjPj1djojox8jZ1xfgBhZmItIVyaD9ETOf+iAiXREebFeSJAmFhYVIT09HdnY2vvjii8uOV1RUYMqUKcjKysLevXsvO3bkyBHcddddbl0jR8xEpCveTJfbvXs3HA4HqqqqUF9fj+XLl2Pt2rUAAJvNhh07dmDr1q0AgIyMDIwbNw79+vVDS0sLNmzY4PaT0xwxE5GuSAb3tyvV1dUhMTERABAbG4uGhgbXscbGRiQkJMBsNsNsNsNqtcJms6GrqwtLly5FUVGR29fIwkxEuuKEwe3tSna7HRaLxfXZZDK5RsHR0dGora2F3W5HW1sbjh49is7OThQXF2PGjBkYNmyY29eoiVbGE/1uViVH2NtUyQEA48hbVMuSBuxTJ0io98yUmitXq7kiN7q7VIkRTvdfNuYtw5h41bLk4M08ZovFgo6Ojv+cS5Lg53epjEZERCArKws5OTmwWq2IiYmByWRCbW0tvvzyS7z66qv497//jWeffRYvv/zyVXM0UZiJiNTizfAiLi4Oe/fuxeTJk1FfX4+oqCjXsdbWVrS1tWHLli1ob2/HjBkzEB8fj127drl+zZ133tlrUQZYmIlIZ7x5T35qaipqamqQkZEBIQRKS0uxceNGhIWFITk5Gc3NzUhLS4O/vz8WLFgAk8l0TTkszESkK960MoxGI4qLiy/b99376gF879iVampq3MphYSYiXfGFt8uxMBORrji1/+AfCzMR6QtHzEREGsPCTESkMd7MylCL4k/+tba2Qghf+KMgIj3w5pFstcg+Yt6+fTtaWlqQlJSE3NxcmM1mXLx4EUuXLsX48ePljiMi8oguWxmbN29GZWUl5syZg7Vr1yI8PBxnz57F3LlzWZiJqM/p8kX5/v7+6N+/P4KCgjBy5EgAl1bJNvjAy6mJ6MdPl2v+JScnY86cOYiKisLs2bORmJiIAwcOYNy4cXJHERF5TJetjCeeeAKffvopDh48iOHDh+Pbb79FdnY2Jk2aJHcUEZHHfGEqgiLT5RISEpCQkKDEqYmIvCL5QGnmPGYi0hVd3vwjItIyXfaYiYi0TJezMoiItIw9ZiIijdF+WWZhJiKdYY/ZTf3V+ivML0ClIJV1OVSJMfQLViUHAOBvVi9LpZWrAaj2+1K1jarm94UMnD4wZtZEYSYiUgtHzEREGsObf0REGqP9sszCTEQ6w1YGEZHG8OYfEZHGsMdMRKQx2i/LLMxEpDO+MGKWfZVsu90u9ymJiGQjebD1FdkL85133omtW7fKfVoiIlkID370FdkL880334zPPvsM06dPx6effir36YmIvOKEcHvrK7L3mM1mMwoLC3H8+HFUVFSguLgYd9xxB0aOHInp06fLHUdE5BFdzmMW4tLfMrfddhtWrVqF9vZ2HDlyBE1NTXJHERF5TBLav/kne2GeOnXqZZ+Dg4ORnJwsdwwR0TXRfllWoDA/9NBDcp+SiEg2vjBdjvOYiUhX+nK2hbtYmIlIV3q8KMySJKGoqAg2mw0BAQEoKSmB1Wp1Ha+oqMDOnTthsVgwa9YsJCUl4cyZM1i0aBGcTieEECguLsbo0aOvmsPCTES64s2Ieffu3XA4HKiqqkJ9fT2WL1+OtWvXAgBsNht27Njheo4jIyMD48aNwyuvvIJHH30UKSkpOHDgAF566SWsXr36qjkszESkK95Ml6urq0NiYiIAIDY2Fg0NDa5jjY2NSEhIgNl8afkwq9UKm82GvLw8BAdfWn7L6XS6jl+N7A+YEBFpmRDC7e1KdrsdFovF9dlkMqGnpwcAEB0djdraWtjtdrS1teHo0aPo7OzE4MGD4e/vj1OnTqG8vBzz5s3r9Ro1MWJWbcK30aRWkqoLlxqGhKiTMzBUlRy1CWePalmqLZKq5mK2PsabWRkWiwUdHR3/OZckwc/vUhmNiIhAVlYWcnJyYLVaERMTg0GDBgEADh8+jGXLluHFF1/stb8McMRMRDrjzSPZcXFxqK6uBgDU19cjKirKday1tRVtbW3YsmULCgoK0NLSgsjISBw+fBgvvPAC/vCHP+C2225z6xo1MWImIlKLNyPm1NRU1NTUICMjA0IIlJaWYuPGjQgLC0NycjKam5uRlpYGf39/LFiwACaTCaWlpeju7sbChQsBAOHh4SguLr5qDgszEenKf+sdu8toNH6vqEZERLh+/t8K7ocffuhxDgszEemKLl9iRESkZXzyj4hIY/iuDCIijXEK7TczWJiJSFfYyiAi0hhdvij/Sg6HA5IkITAwUOkoIqJeab8sK/DkX1NTE+bPn4/c3FzU19fjgQcewC9+8Qt89NFHckcREXlMgnB76yuyj5iXLFmCuXPnor29HbNnz8aHH36I4OBgPP7445g8ebLccUREHtHlrIyenh6MHz8eQgi89NJLGDZs2KUgP7aziajv6XJWxo033ohnn30WTqcTQUFBePnll2GxWHDdddfJHUVE5DFdzsooLy/H/v37MWrUKAQFBWHTpk0IDAxEaWmp3FFERB7z5l0ZapG9MPv5+eHuu+92ff7ujUpERFqgyx4zEZGW6XLETESkZU4feL8cCzMR6Qqf/CMi0hhdzsogItIyjpjd9KtHO1XJce7arEoOABgT1XvK0XDDcHWCAvqpkwNAqn5PtSzDmHjVsqDi6ulqMd14c19fgkc4YiYi0hiOmImINEaXj2QTEWkZWxlERBojOGImItIWPpJNRKQxfCSbiEhjOGImItIYp6TzHrMQAgaDQckIIiKP6HJWxpdffolly5bh1KlT+Prrr3Hrrbdi5MiRWLhwIVcxIaI+p8se87Jly7B48WKEh4ejvr4e+/btQ0pKCgoKClBRUSF3HBGRR3yhx2yU+4R2ux3h4eEAgNjYWPz973/HT37yE5w/f17uKCIijwkh3N76iuwj5hEjRqCwsBATJ07Evn37MGbMGPz5z39Gv37qvQCHiOiH+MLNP9lHzGVlZYiOjkZNTQ3Gjh2LBQsWIDQ0FC+99JLcUUREHpMg3N76iuwj5oCAAGRlZV22LzY2Vu4YIqJrosubf0REWubNaz8lSUJRURFsNhsCAgJQUlICq9XqOl5RUYGdO3fCYrFg1qxZSEpKQmtrK5577jlcvHgRoaGhKCsr67W1K3srg4hIy4QHP660e/duOBwOVFVVITc3F8uXL3cds9ls2LFjB959911s2LABK1euRGdnJ9asWYP7778fmzdvxi233IKqqqper5GFmYh0RRLC7e1KdXV1SExMBHCpRdvQ0OA61tjYiISEBJjNZpjNZlitVthstsu+ZuLEiTh06FCv18jCTES6IgnJ7e1KdrsdFovF9dlkMqGnpwcAEB0djdraWtjtdrS1teHo0aPo7OyE3W5HcPClJcWCgoLQ3t7e6zWyx0xEuuLNzT+LxYKOjg7XZ0mS4Od3qYxGREQgKysLOTk5sFqtiImJwaBBg1xfExgYiI6ODgwYMKDXHI6YiUhXvHnAJC4uDtXV1QCA+vp6REVFuY61traira0NW7ZsQUFBAVpaWhAZGYm4uDjs378fAFBdXY34+N4X/zUIX5g7QkSkAd/NyvjnP/8JIQRKS0tRXV2NsLAwJCcnY+nSpfjHP/4Bf39/5Obm4vbbb8c333yDvLw8dHR0YNCgQVixYgX69+9/1RwWZiIijWErg4hIY1iYiYg0hoWZiEhjfG66XG+PRMrt2LFj+N3vfofKykrFMrq7u7Fo0SKcPn0aDocDc+bMwd13361IltPpxOLFi9HU1ASTyYSysjKEhYUpkvWdb7/9FlOnTsWGDRsQERGhWM6DDz7omi86YsQIlJWVKZKzfv167NmzB93d3cjMzMTDDz+sSM57772H999/HwDQ1dWFzz77DDU1NW5Nt/JUd3c3Fi5ciNOnT8NoNOL5559X7L+Vw+FAfn4+vvrqK1gsFhQWFmLUqFGKZPks4WN27dol8vLyhBBCHD16VDz55JOKZVVUVIj7779fPPzww4plCCHEtm3bRElJiRBCiNbWVnHXXXcplvXJJ5+IhQsXCiGEOHz4sKJ/fkII4XA4xNy5c8U999wjTp48qVjOxYsXxZQpUxQ7/3cOHz4sZs+eLZxOp7Db7WLlypWKZwohRFFRkXjnnXcUO/8nn3wi5s+fL4QQ4uDBg+Kpp55SLKuyslIsXrxYCCFEY2OjmDFjhmJZvsrnWhlXeyRSbmFhYVi1apVi5//Oz3/+czzzzDOuzyaTSbGslJQUPP/88wCAM2fOYOjQoYplAUB5eTkyMjIQGhqqaM6JEyfQ2dmJGTNmYPr06aivr1ck5+DBg4iKisK8efPw5JNPYtKkSYrk/H/Hjx/HyZMnkZ6erlhGeHg4nE4nJEmC3W53PTShhJMnT2LixIkAgNGjR6OxsVGxLF/lc62MH3okUolvpHvvvRfNzc2yn/dKQUFBAC793ubPn49f//rXiub5+fkhLy8Pn3zyCVauXKlYznvvvYfBgwcjMTFR8WXFAgMDMXPmTDz88MP4/PPPkZOTg48//lj274u2tjacOXMG69atQ3NzM+bMmYOPP/5Y0UWH169fj3nz5il2fgDo378/Tp8+jfvuuw9tbW1Yt26dYlljxozB3r17kZKSgmPHjuHs2bNwOp2KDkh8jc+NmK/2SKQva2lpwfTp0zFlyhQ88MADiueVl5dj165dWLJkCS5cuKBIxvbt23Ho0CFkZ2fjs88+Q15eHs6dO6dIVnh4OH75y1/CYDAgPDwcISEhimSFhIRgwoQJCAgIwOjRo2E2m9Ha2ip7znfOnz+PU6dOYdy4cYplAMCmTZswYcIE7Nq1C3/84x+xcOFCdHV1KZKVlpYGi8WC6dOnY+/evbj11ltZlK/gc4X5ao9E+qpvvvkGM2bMwG9/+1tMmzZN0awPPvgA69evBwD069cPBoNBsf8p3n77bbz11luorKzEmDFjUF5erthK6du2bXO9gvHs2bOw2+2KZMXHx+PAgQMQQuDs2bPo7OxESEiI7DnfOXLkCMaPH6/Y+b8zYMAA143TgQMHoqenB06nU5Gs48ePIz4+HpWVlUhJScHIkSMVyfFlPjfUTE1NRU1NDTIyMlyPRPq6devW4fz581izZg3WrFkDAHjttdcQGBgoe9Y999yD/Px8ZGVloaenB4sWLYLZbJY9R23Tpk1Dfn4+MjMzYTAYUFpaqsi/pJKSknDkyBFMmzYNQggUFhYqOtpramrCiBEjFDv/d371q19h0aJFeOSRR9Dd3Y1nn32218eGr5XVasUrr7yCDRs2IDg4GC+88IIiOb6Mj2QTEWmMz7UyiIh+7FiYiYg0hoWZiEhjWJiJiDSGhZmISGNYmImINIaFmYhIY/4Prin1TOtGZuwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25ba8978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      "0 I have said you should speak presently.\n",
      "1 And I see very few pearls in the room except mine.\n",
      "2 O Cicero, I haue seene Tempests, when the scolding Winds Haue riu'd the knottie Oakes, and I haue seene Th' ambitious Ocean swell, and rage, and foame, To be exalted with the threatning Clouds:\n",
      "3 You see he wasn't well enough acquainted with Buster to know that Buster is quite as smart as he is, and perhaps a little bit smarter.\n",
      "4 It is I, you women, I make my way, I am stern, acrid, large, undissuadable, but I love you, I do not hurt you any more than is necessary for you, I pour the stuff to start sons and daughters fit for these States, I press with slow rude muscle, I brace myself effectually, I listen to no entreaties, I dare not withdraw till I deposit what has so long accumulated within me.\n",
      "5 He shipp'd as green-hand boy, and sail'd away, (took some sudden, vehement notion;)\n",
      "6 You see, I wanted to go into the detective service, especially the anti-dynamite business.\n",
      "7 There was a languor, a want of spirits, a want of union, which could not be got over.\n",
      "8 When I went into the room full of his supporters I expected to be received with a roar of laughter, or (if they were too far gone) with a roar of indignation at the insult.\n",
      "9 Then tell my woman she need not come to me, and let nobody INTERUDE on me do you 'EAR?\n"
     ]
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "#Generating a key for the plot.\n",
    "print('Key:')\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Classification Models \n",
    "\n",
    "I'm going to attempt the supervised classification models with and without the k-means clustering predictions as features to see how well the different models perform. I will use GridSearchCV to make sure I can obtain the best scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
